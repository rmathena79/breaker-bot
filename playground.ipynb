{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a573b8d-3b18-4b51-924b-a3154e8f09b6",
   "metadata": {},
   "source": [
    "# Code Breaker Playground\n",
    "\n",
    "I suggest you hide the cells in this section, as they are boilerplate imports, initialization, and some convenience functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46153d99-5f2e-4095-87fb-5b9aff46bfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 20:16:00.749969: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-02 20:16:00.773952: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-02 20:16:00.779202: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Disable some chatty warnings from Tensorflow:\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\"\n",
    "\n",
    "# Still trying to disable warnings. It's harder than you'd think!\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from credentials import CONNECTION_INFO\n",
    "from constants import *\n",
    "\n",
    "import encoders\n",
    "import db_connect\n",
    "import helpers\n",
    "import tf_helpers\n",
    "import models\n",
    "import crackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c3a6e81-1a80-4dc8-afdc-ed22a17ab422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733199365.653616  168107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733199365.762191  168107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733199365.762323  168107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733199365.768831  168107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733199365.768987  168107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733199365.769034  168107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733199367.383287  168107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733199367.383546  168107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733199367.383642  168107 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 699 ms, total: 1.75 s\n",
      "Wall time: 2.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CAESAR_KEY_MODEL = models.load_model(models.CAESAR_KEY_MODEL_PATH)\n",
    "CAESAR_TEXT_MODEL = models.load_model(models.CAESAR_TEXT_MODEL_PATH)\n",
    "SUBSTITUTION_KEY_MODEL = None\n",
    "SUBSTITUTION_TEXT_MODEL = None\n",
    "\n",
    "CAESAR_CHUNK_SIZE = CAESAR_TEXT_MODEL.input_shape[2]\n",
    "SUBSTITUTION_CHUNK_SIZE = None\n",
    "\n",
    "CAESAR_SCALER = helpers.load_scaler_from_file(helpers.get_recommended_scaler_path(encoders.ENCODER_CAESAR, CAESAR_CHUNK_SIZE, temp=False))\n",
    "SUBSTITUTION_SCALER = None\n",
    "\n",
    "MAX_DISPLAY_LENGTH = 100\n",
    "MAX_CAESAR_KEY = len(encoders.CHARSET)-1\n",
    "\n",
    "CAESAR_CRACKER = crackers.Caesar_Cracker(CAESAR_SCALER, CAESAR_KEY_MODEL, CAESAR_TEXT_MODEL, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5139fcca-2b6e-4520-9006-cdafcfc8b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a string short enough to display, optionally with lines above and below if it is a multi-line string\n",
    "SEPARATOR_LINE = \"---------------------------------------------------------------------------\"\n",
    "def displayable(message: str, add_lines_to_multiline= True) -> str:\n",
    "    if len(message) < MAX_DISPLAY_LENGTH:\n",
    "        result = message\n",
    "    else:    \n",
    "        result = message[0 : MAX_DISPLAY_LENGTH-3] + \"...\"\n",
    "\n",
    "    if (\"\\n\" in result) and add_lines_to_multiline:\n",
    "        # Multi-line string\n",
    "        result = (SEPARATOR_LINE + \"\\n\" + result + \"\\n\" + SEPARATOR_LINE + \"\\n\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def ms_per_char(elapsed_seconds, characters: str) -> float:\n",
    "    ms = elapsed_seconds * 1000\n",
    "    char_count = len(characters)\n",
    "    return float(ms) / float(char_count)\n",
    "\n",
    "def work_magic(message: str, key: int):\n",
    "    if (message is None) or (len(message) < 1):\n",
    "        raise Exception(\"Message must be a non-empty string\")\n",
    "    if (key < 1 or key > MAX_CAESAR_KEY):\n",
    "        raise Exceptions(\"Key out of bounds\")\n",
    "\n",
    "    # Simplify the string so it uses the right characterset\n",
    "    simplified = encoders.encode_simple(message)\n",
    "    if len(simplified) < 1:\n",
    "        raise Exception(\"Message became an empty string after simplification. It must have been all special characters.\")\n",
    "\n",
    "    if len(simplified) < CAESAR_CHUNK_SIZE // 2:\n",
    "        print(f\"Your string is only {len(simplified)} characters after simplification.\")\n",
    "        print(f\"The model has a hard time with short strings. But so do people!\")\n",
    "        print()    \n",
    "\n",
    "    # Make the string long enough to be at least one chunk, and divisible by the chunk size\n",
    "    padded = simplified\n",
    "    while len(padded) < CAESAR_CHUNK_SIZE:\n",
    "        padded = padded + simplified            \n",
    "    plaintext = padded[0: len(padded) - len(padded) % CAESAR_CHUNK_SIZE]\n",
    "    \n",
    "    print(\"This is your original message:\")\n",
    "    print(displayable(message))\n",
    "    print()\n",
    "    print(\"This is the plaintext we will work with:\")\n",
    "    print(displayable(plaintext))\n",
    "    print()\n",
    "\n",
    "    ciphertext = encoders.encode_caesar(plaintext, key)\n",
    "    print(f\"After encrypting with key {key}, this is the ciphertext:\")\n",
    "    print(displayable(ciphertext))\n",
    "    print()\n",
    "\n",
    "    start_time = time.time()\n",
    "    inferred_key = CAESAR_CRACKER.infer_key_with_model(ciphertext)\n",
    "    good_key = key == inferred_key    \n",
    "    elapsed_seconds = (time.time() - start_time)\n",
    "\n",
    "    print(f'The model predicted a key of {inferred_key}, which is {\"correct.\" if good_key else \"INCORRECT!\"}')\n",
    "    print(f\"Finding the key took {elapsed_seconds:.2f} seconds, or {ms_per_char(elapsed_seconds, ciphertext):.2f} ms per character.\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    inferred_text = CAESAR_CRACKER.infer_text_with_model(ciphertext)\n",
    "    elapsed_seconds = (time.time() - start_time)\n",
    "\n",
    "    print()\n",
    "    print(f\"The model predicted this text:\")\n",
    "    print(displayable(inferred_text))\n",
    "    print(f\"Finding the text took {elapsed_seconds:.2f} seconds, or {ms_per_char(elapsed_seconds, ciphertext):.2f} ms per character.\")\n",
    "\n",
    "    (good, bad, total, good_pct) = helpers.good_bad_string_match(plaintext, inferred_text)\n",
    "    random_pct = float(1) / float(len(encoders.CHARSET))\n",
    "    print(f\"The model's string is {good_pct:.2%} right.\")\n",
    "    print(f\"Random guessing would tend to be about {random_pct:.2%} right.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef56e1-c852-46fe-a861-8dea616168e9",
   "metadata": {},
   "source": [
    "# The Fun Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ce2d9f-73f1-4a3d-bcd6-c935fc12b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your original message:\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut lab...\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "This is the plaintext we will work with:\n",
      "LOREM IPSUM DOLOR SIT AMET, CONSECTETUR ADIPISCING ELIT, SED DO EIUSMOD TEMPOR INCIDIDUNT UT LABO...\n",
      "\n",
      "After encrypting with key 61, this is the ciphertext:\n",
      "---------------------------------------------------------------------------\n",
      "KNQDL?HORTL?CNKNQ?RHS?\n",
      "LDS\"?BNMRDBSDSTQ?\n",
      "CHOHRBHMF?DKHS\"?RDC?CN?DHTRLNC?SDLONQ?HMBHCHCTMS?TS?K\n",
      "AN...\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "The model predicted a key of 61, which is correct.\n",
      "Finding the key took 0.12 seconds, or 0.46 ms per character.\n",
      "\n",
      "The model predicted this text:\n",
      "FHKCIBJNOKDCHMIIKBIEO AMFT> LPOSDCSDRSP>?IGOGRBGLE?ILHS/ OED JO JHTRLND?REMPOR?KNCHDHDTMT?RS MAJN...\n",
      "Finding the text took 0.11 seconds, or 0.42 ms per character.\n",
      "The model's string is 31.25% right.\n",
      "Random guessing would tend to be about 1.61% right.\n"
     ]
    }
   ],
   "source": [
    "MY_MESSAGE = \"\"\"\n",
    "Set this to whatever you like. The model does best with standard English text, and longer strings are easier\n",
    "\"\"\"\n",
    "MY_KEY = random.randint(1, MAX_CAESAR_KEY)\n",
    "\n",
    "work_magic(MY_MESSAGE, MY_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630963c9-3b7f-410a-b410-49a3c938f232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
