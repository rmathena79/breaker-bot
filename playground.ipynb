{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a573b8d-3b18-4b51-924b-a3154e8f09b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Code Breaker Playground\n",
    "\n",
    "I suggest you hide the cells in this section, as they are boilerplate imports, initialization, and some convenience functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46153d99-5f2e-4095-87fb-5b9aff46bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Disable some chatty warnings from Tensorflow:\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\"\n",
    "\n",
    "# Still trying to disable warnings. It's harder than you'd think!\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from credentials import CONNECTION_INFO\n",
    "from constants import *\n",
    "\n",
    "import encoders\n",
    "import db_connect\n",
    "import helpers\n",
    "import tf_helpers\n",
    "import models\n",
    "import crackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a6e81-1a80-4dc8-afdc-ed22a17ab422",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAESAR_KEY_MODEL = models.load_model(models.CAESAR_KEY_MODEL_PATH)\n",
    "CAESAR_TEXT_MODEL = models.load_model(models.CAESAR_TEXT_MODEL_PATH)\n",
    "SUBSTITUTION_KEY_MODEL = None\n",
    "SUBSTITUTION_TEXT_MODEL = None\n",
    "\n",
    "CAESAR_CHUNK_SIZE = CAESAR_TEXT_MODEL.input_shape[2]\n",
    "SUBSTITUTION_CHUNK_SIZE = None\n",
    "\n",
    "CAESAR_SCALER = helpers.load_scaler_from_file(helpers.get_recommended_scaler_path(encoders.ENCODER_CAESAR, CAESAR_CHUNK_SIZE, temp=False))\n",
    "SUBSTITUTION_SCALER = None\n",
    "\n",
    "MAX_DISPLAY_LENGTH = 100\n",
    "MAX_CAESAR_KEY = len(encoders.CHARSET)-1\n",
    "\n",
    "CAESAR_CRACKER = crackers.Caesar_Cracker(CAESAR_SCALER, CAESAR_KEY_MODEL, CAESAR_TEXT_MODEL, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139fcca-2b6e-4520-9006-cdafcfc8b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a string short enough to display, optionally with lines above and below if it is a multi-line string\n",
    "SEPARATOR_LINE = \"---------------------------------------------------------------------------\"\n",
    "def displayable(message: str, add_lines_to_multiline= True) -> str:\n",
    "    if len(message) < MAX_DISPLAY_LENGTH:\n",
    "        result = message\n",
    "    else:    \n",
    "        result = message[0 : MAX_DISPLAY_LENGTH-3] + \"...\"\n",
    "\n",
    "    if (\"\\n\" in result) and add_lines_to_multiline:\n",
    "        # Multi-line string\n",
    "        result = (SEPARATOR_LINE + \"\\n\" + result + \"\\n\" + SEPARATOR_LINE + \"\\n\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def ms_per_char(elapsed_seconds, characters: str) -> float:\n",
    "    ms = elapsed_seconds * 1000\n",
    "    char_count = len(characters)\n",
    "    return float(ms) / float(char_count)\n",
    "\n",
    "def work_magic(message: str, key: int):\n",
    "    if (message is None) or (len(message) < 1):\n",
    "        raise Exception(\"Message must be a non-empty string\")\n",
    "    if (key < 1 or key > MAX_CAESAR_KEY):\n",
    "        raise Exceptions(\"Key out of bounds\")\n",
    "\n",
    "    # Simplify the string so it uses the right characterset\n",
    "    simplified = encoders.encode_simple(message)\n",
    "    if len(simplified) < 1:\n",
    "        raise Exception(\"Message became an empty string after simplification. It must have been all special characters.\")\n",
    "\n",
    "    if len(simplified) < CAESAR_CHUNK_SIZE // 2:\n",
    "        print(f\"Your string is only {len(simplified)} characters after simplification.\")\n",
    "        print(f\"The model has a hard time with short strings.\")\n",
    "        print()    \n",
    "\n",
    "    # Make the string long enough to be at least one chunk, and divisible by the chunk size\n",
    "    padded = simplified\n",
    "    while len(padded) < CAESAR_CHUNK_SIZE:\n",
    "        padded = padded + simplified            \n",
    "    plaintext = padded[0: len(padded) - len(padded) % CAESAR_CHUNK_SIZE]\n",
    "    \n",
    "    print(\"This is your original message:\")\n",
    "    print(displayable(message))\n",
    "    print()\n",
    "    print(\"This is the plaintext we will work with:\")\n",
    "    print(displayable(plaintext))\n",
    "    print()\n",
    "\n",
    "    ciphertext = encoders.encode_caesar(plaintext, key)\n",
    "    print(f\"After encrypting with key {key}, this is the ciphertext:\")\n",
    "    print(displayable(ciphertext))\n",
    "    print()\n",
    "\n",
    "    start_time = time.time()\n",
    "    inferred_key = CAESAR_CRACKER.infer_key_with_model(ciphertext)\n",
    "    good_key = key == inferred_key    \n",
    "    elapsed_seconds = (time.time() - start_time)\n",
    "\n",
    "    print(f'The model predicted a key of {inferred_key}, which is {\"correct.\" if good_key else \"INCORRECT!\"}')\n",
    "    print(f\"Finding the key took {elapsed_seconds:.2f} seconds, or {ms_per_char(elapsed_seconds, ciphertext):.2f} ms per character.\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    inferred_text = CAESAR_CRACKER.infer_text_with_model(ciphertext)\n",
    "    elapsed_seconds = (time.time() - start_time)\n",
    "\n",
    "    print()\n",
    "    print(f\"The model predicted this text:\")\n",
    "    print(displayable(inferred_text))\n",
    "    print(f\"Finding the text took {elapsed_seconds:.2f} seconds, or {ms_per_char(elapsed_seconds, ciphertext):.2f} ms per character.\")\n",
    "\n",
    "    (good, bad, total, good_pct) = helpers.good_bad_string_match(plaintext, inferred_text)\n",
    "    random_pct = float(1) / float(len(encoders.CHARSET))\n",
    "    print(f\"The model's string is {good_pct:.2%} right.\")\n",
    "    print(f\"Random guessing would tend to be about {random_pct:.2%} right.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef56e1-c852-46fe-a861-8dea616168e9",
   "metadata": {},
   "source": [
    "# The Fun Part\n",
    "Set the message you want to encrypt, and see how well the model does with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce2d9f-73f1-4a3d-bcd6-c935fc12b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_MESSAGE = \"\"\"\n",
    "Set this to whatever you like. The model does best with standard English text, and longer strings are easier.\n",
    "\"\"\"\n",
    "MY_KEY = random.randint(1, MAX_CAESAR_KEY)\n",
    "\n",
    "# Fun fact: If you use key #39 with my default string, Tensorflow will hang!\n",
    "work_magic(MY_MESSAGE, MY_KEY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
