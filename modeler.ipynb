{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca2471e-572c-4233-b18c-e8e03e8cf40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 16:11:09.936615: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 16:11:09.950556: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-01 16:11:09.962806: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-01 16:11:09.967050: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 16:11:09.979741: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import pathlib\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from credentials import CONNECTION_INFO\n",
    "from constants import *\n",
    "\n",
    "import encoders\n",
    "import db_connect\n",
    "import helpers\n",
    "\n",
    "# Callbacks for use with TensorFlow\n",
    "from tf_helpers import modulo_output, modulo_distance_loss, modulo_distance_accuracy, modulo_rounded_accuracy, initialize_save_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088ab2d-0294-47b0-8528-98cbbbfb15bd",
   "metadata": {},
   "source": [
    "## Config\n",
    "This notebook has a lot of options to adjust, most of which are controlled here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9bdcd65-ceca-4b1a-921a-4544e38b37b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 32, 256, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENCODER = encoders.ENCODER_CAESAR\n",
    "CHUNK_SIZE = 512 # Was 512\n",
    "PROCESSING_UNITS = CHUNK_SIZE // 16 # Was // 4\n",
    "\n",
    "EXTRA_CHECKS = True # Whether to run some (potentially slow) debug checks\n",
    "\n",
    "INFER_TEXT = False # Text inferrence isn't really working. I don't know how to combine the time-distributed results.\n",
    "INFER_KEY = not INFER_TEXT\n",
    "\n",
    "if INFER_TEXT:\n",
    "    MAIN_ACCURACY_METRIC = \"mae\"\n",
    "    LOSS_METRIC = \"mean_squared_error\"\n",
    "    OUTPUT_SIZE = CHUNK_SIZE\n",
    "    OPTIMIZER = \"sgd\"\n",
    "else:\n",
    "    MAIN_ACCURACY_METRIC = \"mae\"\n",
    "    LOSS_METRIC = \"mae\"\n",
    "    OPTIMIZER = \"adamax\"    \n",
    "\n",
    "    if ENCODER == encoders.ENCODER_CAESAR:\n",
    "        OUTPUT_SIZE = 1\n",
    "    elif ENCODER == encoders.ENCODER_SUBST:\n",
    "        OUTPUT_SIZE = len(encoders.CHARSET)\n",
    "    else:\n",
    "        raise Exception(f\"Unsupported encoder {ENCODER}\")\n",
    "\n",
    "ENCRYPTED_FILE_LIMIT = -1 # -1 to disable limit\n",
    "\n",
    "BASE_TRAIN_PCT = 0.75   # Start here. If train or test count would exceed the max, reduce it. Note 0.75 is the default.\n",
    "MAX_TRAIN_COUNT = -1 # -1 to disable; some setups start running out of memory around 100K\n",
    "MAX_TEST_COUNT =  -1 # -1 to disable\n",
    "SPLIT_SEED = 42\n",
    "\n",
    "LOAD_BEST_MODEL = False # If False, a new model will be created from scratch\n",
    "SAVE_BEST_MODEL = True\n",
    "BEST_PATH = './saved_models/best.keras'\n",
    "\n",
    "# Whether to run the tuner or the hard-coded network build code\n",
    "TUNE_NETWORK = False\n",
    "TUNE_QUICKLY = False # Set True to sanity check the model builder\n",
    "BUILD_NETWORK = not TUNE_NETWORK\n",
    "TRAIN_MODEL = BUILD_NETWORK and not LOAD_BEST_MODEL\n",
    "\n",
    "TUNER_DIRECTORY = \"tuner_projects\"\n",
    "TUNER_PROJECT_NAME = \"KT\"\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = int(max(32, round(256 * (512/CHUNK_SIZE)))) # Default is 32 -- going higher speeds things up a LOT, but may cause memory problems\n",
    "SCALE = True\n",
    "\n",
    "CHUNK_SIZE, PROCESSING_UNITS, BATCH_SIZE, OUTPUT_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ec896-6840-4696-bebd-c0419f8a1f69",
   "metadata": {},
   "source": [
    "# Data Retrieval and Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789ab2e5-5e11-4812-91be-bb9a63acb6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 35, (95958, 512), (95958,), 393044096, 767776)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = db_connect.DB(CONNECTION_INFO)\n",
    "\n",
    "with db.get_session() as session:\n",
    "    # Get database IDs for encoders and key types\n",
    "    (encoder_ids, key_type_id) = db.get_id_maps(session)\n",
    "\n",
    "    # Map source ID to plaintext file (1) details, and source ID to corresponding ciphertext files (1+) details\n",
    "    (sid_to_p, sid_to_c) = db.get_source_maps(session, ENCRYPTED_FILE_LIMIT, encoder_ids[ENCODER], test_only=False)\n",
    "\n",
    "    # Get the features (X, the cipher texts as offsets) and targets (y, either the plain texts as offsets OR the key).\n",
    "    (X, y_keys, y_texts) = db.get_features_and_targets(session, sid_to_p, sid_to_c, ENCODER, CHUNK_SIZE)\n",
    "\n",
    "X = np.array(X)\n",
    "if INFER_KEY:\n",
    "    y = np.array(y_keys)\n",
    "if INFER_TEXT:\n",
    "    y = np.array(y_texts)\n",
    "        \n",
    "len(sid_to_p), len(sid_to_c), X.shape, y.shape, sys.getsizeof(X), sys.getsizeof(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e72d2c0-2cf4-4d4e-89af-46021e40bbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 960 strings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8180147, 49080882)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugging...\n",
    "\n",
    "# Get ALL the texts in one big string, for debugging\n",
    "all_plaintexts = \"\"\n",
    "all_ciphertexts = \"\"\n",
    "for sid in sid_to_p:\n",
    "    all_plaintexts += helpers.read_text_file(sid_to_p[sid].path)\n",
    "    for c in sid_to_c[sid]:\n",
    "        all_ciphertexts += helpers.read_text_file(c.path)\n",
    "\n",
    "# Make sure specified text occurs somewhere in the texts.\n",
    "# These raise exceptions if not found.\n",
    "def check_in_plaintext(to_check: str):\n",
    "    if to_check not in all_plaintexts:\n",
    "        raise Exception(f\"Plaintext not found: {to_check}\")\n",
    "\n",
    "def check_in_ciphertext(to_check: str):\n",
    "    if to_check not in all_ciphertexts:\n",
    "        raise Exception(f\"Ciphertext not found: {to_check}\")\n",
    "\n",
    "if EXTRA_CHECKS:\n",
    "    checks = round( len(X) * 0.01)\n",
    "    print(f\"Checking {checks} strings\")\n",
    "    for _ in range(checks):\n",
    "        i = random.randint(0, len(X)-1)\n",
    "        check_in_plaintext(encoders.offsets_to_string(y_texts[i].astype(int)))\n",
    "        check_in_ciphertext(encoders.offsets_to_string(X[i].astype(int)))\n",
    "\n",
    "len(all_plaintexts), len(all_ciphertexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55451fa-ee72-4835-b18a-d03d44899412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count is 71968\n",
      "Test count is 23990\n",
      "Checking 240 strings\n"
     ]
    }
   ],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "# Note we have excluded \"test_only\" files above, they will be used for later validation.\n",
    "\n",
    "train_count = int(round(len(y) * BASE_TRAIN_PCT))\n",
    "if train_count > MAX_TRAIN_COUNT and MAX_TRAIN_COUNT > -1:\n",
    "    print(f\"Train count would be {train_count}\")\n",
    "    train_count = int(MAX_TRAIN_COUNT)\n",
    "print(f\"Train count is {train_count}\")\n",
    "\n",
    "test_count = len(y) - train_count\n",
    "if test_count > MAX_TEST_COUNT and MAX_TEST_COUNT > -1:\n",
    "    print(f\"Test count would be {test_count}\")\n",
    "    test_count = int(MAX_TEST_COUNT)\n",
    "print(f\"Test count is {test_count}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_count, test_size=test_count, random_state=SPLIT_SEED)\n",
    "\n",
    "if EXTRA_CHECKS:\n",
    "    checks = max(10, round( min(len(X_train), len(X_test)) * 0.01))\n",
    "    print(f\"Checking {checks} strings\")\n",
    "    for _ in range(checks):\n",
    "        i = random.randint(0, len(X_train)-1)\n",
    "        check_in_ciphertext(encoders.offsets_to_string(X_train[i].astype(int)))\n",
    "\n",
    "        i = random.randint(0, len(X_test)-1)\n",
    "        check_in_ciphertext(encoders.offsets_to_string(X_test[i].astype(int)))\n",
    "\n",
    "# The pre-split data sets are no longer needed, and take up a lot of memory, so get rid of them\n",
    "if not EXTRA_CHECKS:\n",
    "    del X\n",
    "    del y\n",
    "    del y_keys\n",
    "    del y_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5fd198-2be6-4f66-91ff-0bbb1ccb819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 240 strings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((71968, 512),\n",
       " (23990, 512),\n",
       " array([ 0.14185034, -0.21097266,  0.84917754,  0.49584046, -1.27538753,\n",
       "        -0.21097319, -1.26778865,  1.20328198,  0.13332543, -0.91000704,\n",
       "        -0.56356898, -1.27079797, -0.21048943,  0.49693745, -1.61955243,\n",
       "        -0.91552221]),\n",
       " array([ 0.494275  ,  1.20021122,  0.14344914,  0.49584046, -0.92249056,\n",
       "        -1.27108807,  0.495873  , -1.61867667, -1.27803955, -0.20391186,\n",
       "         0.49319444, -0.56454613,  1.20133317,  0.49693745,  0.85075048,\n",
       "         1.20181321]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if SCALE:\n",
    "    # Create a StandardScaler instances\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the StandardScaler\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    \n",
    "    # Scale the data\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)    \n",
    "else:\n",
    "    # Leave the inputs unscaled\n",
    "    X_train_scaled = X_train\n",
    "    X_test_scaled = X_test\n",
    "\n",
    "if SCALE and EXTRA_CHECKS:\n",
    "    checks = max(10, round( min(len(X_train), len(X_test)) * 0.01))\n",
    "    print(f\"Checking {checks} strings\")\n",
    "    for _ in range(checks):\n",
    "        i = random.randint(0, len(X_train_scaled)-1)\n",
    "        scaled = X_train_scaled[i]\n",
    "        unscaled = X_scaler.inverse_transform([scaled]).round().astype(int)[0]\n",
    "        check_in_ciphertext(encoders.offsets_to_string(unscaled))\n",
    "\n",
    "        i = random.randint(0, len(X_test_scaled)-1)\n",
    "        scaled = X_test_scaled[i]\n",
    "        unscaled = X_scaler.inverse_transform([scaled]).round().astype(int)[0]\n",
    "        check_in_ciphertext(encoders.offsets_to_string(unscaled))\n",
    "        \n",
    "to_show = min(16, CHUNK_SIZE)\n",
    "X_train_scaled.shape, X_test_scaled.shape, X_train_scaled[0][0:to_show], X_test_scaled[0][0:to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fffa6ffe-b96c-49ff-abe9-858cd87dabde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: (71968, 512), (23990, 512), (71968,), (23990,)\n",
      "Final    shapes: (71968, 512, 1), (71968, 512, 1), (23990, 512, 1), (23990, 512, 1), (71968, 1, 1), (23990, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data as required for the model\n",
    "\n",
    "print(f\"Original shapes: {X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}\")\n",
    "\n",
    "X_train = X_train.reshape((-1, CHUNK_SIZE, 1)) \n",
    "X_train_scaled = X_train_scaled.reshape((-1, CHUNK_SIZE, 1)) \n",
    "X_test = X_test.reshape((-1, CHUNK_SIZE, 1)) \n",
    "X_test_scaled = X_test_scaled.reshape((-1, CHUNK_SIZE, 1)) \n",
    "y_train = y_train.reshape((-1, OUTPUT_SIZE, 1)) \n",
    "y_test = y_test.reshape((-1, OUTPUT_SIZE, 1))\n",
    "\n",
    "print(f\"Final    shapes: {X_train.shape}, {X_train_scaled.shape}, {X_test.shape}, {X_test_scaled.shape}, {y_train.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340dfc6-d8e6-461c-87af-f2627f638908",
   "metadata": {},
   "source": [
    "# Hyperband Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ab864b-b88b-4dac-b504-c58c4fbdc37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_tuner\n",
    "\n",
    "MAX_EPOCHS_PER_MODEL = 20 # Meant to get a decent idea of parameter, not create a final model. Behaves oddly below 3.\n",
    "HYPERBAND_ITERATIONS = 2  # \"Number of times to iterate over the full Hyperband algorithm\"\n",
    "EXECUTIONS_PER_TRIAL = 2  # Training from scratch\n",
    "SEARCH_FIT_EPOCHS = 20    # Epochs for each attempt to do a fit, I think. Not sure how this relates to MAX_EPOCHS_PER_MODEL.\n",
    "OVERWRITE = True          # I'm hoping to be able to interrupt a run and resume it later\n",
    "\n",
    "input_shape = (None, 1, CHUNK_SIZE)\n",
    "mr_t = model_tuner.ModelTuner(input_shape, OUTPUT_SIZE, CHUNK_SIZE, BATCH_SIZE)\n",
    "\n",
    "# All-encompassing optimization parameter choices. Do not try to use all of them at once...\n",
    "mr_t.CHOICES_PROCESSING_UNITS = [1, CHUNK_SIZE // 16, CHUNK_SIZE // 4, CHUNK_SIZE, CHUNK_SIZE * 2]\n",
    "mr_t.CHOICES_ACTIVATIONS = [\"elu\", \"gelu\", \"hard_sigmoid\", \"hard_silu\", \"hard_swish\", \"leaky_relu\", \"linear\", \"log_softmax\", \"mish\",\n",
    "        \"relu\", \"relu6\", \"selu\", \"sigmoid\", \"silu\", \"softmax\", \"softplus\", \"softsign\", \"swish\", \"tanh\"]\n",
    "mr_t.CHOICES_FANCY_TOPO = [\"GRU\", \"RNN\", \"LSTM\", \"GRU-RNN\", \"GRU-LSTM\", \"GRU-RNN-LSTM\"]\n",
    "mr_t.CHOICES_USE_OUTPUT_LIMITER = [True, False] # Prefers True\n",
    "mr_t.CHOICES_OPTIMIZER = [\"adamax\", \"sgd\", \"RMSProp\"]\n",
    "\n",
    "# Narrow down the choices as needed.\n",
    "mr_t.CHOICES_PROCESSING_UNITS = [1, 2, CHUNK_SIZE//16, CHUNK_SIZE//4, CHUNK_SIZE//2, CHUNK_SIZE, CHUNK_SIZE*2]\n",
    "mr_t.CHOICES_ACTIVATIONS = [\"tanh\", \"sigmoid\"]\n",
    "mr_t.CHOICES_FANCY_TOPO = [\"LSTM\"]\n",
    "mr_t.CHOICES_USE_OUTPUT_LIMITER = [True]\n",
    "mr_t.CHOICES_OPTIMIZER = [\"adamax\"]\n",
    "\n",
    "if TUNE_QUICKLY:\n",
    "    MAX_EPOCHS_PER_MODEL = 3\n",
    "    HYPERBAND_ITERATIONS = 1\n",
    "    EXECUTIONS_PER_TRIAL = 1\n",
    "    SEARCH_FIT_EPOCHS = 4\n",
    "\n",
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    return mr_t.CreateModel(hp)\n",
    "\n",
    "# Run the kerastuner search for best hyperparameters\n",
    "if TUNE_NETWORK:\n",
    "    if USE_CUSTOM_METRICS:\n",
    "        objective = kt.Objective(\"modulo_distance_accuracy\", direction=\"max\")\n",
    "    else:\n",
    "        objective = kt.Objective(f\"{MAIN_ACCURACY_METRIC}\", direction=\"max\")\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        create_model,\n",
    "        objective=objective,\n",
    "        max_epochs=MAX_EPOCHS_PER_MODEL,\n",
    "        hyperband_iterations=HYPERBAND_ITERATIONS,\n",
    "        executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
    "        overwrite=OVERWRITE,\n",
    "        directory=TUNER_DIRECTORY,\n",
    "        project_name=TUNER_PROJECT_NAME)\n",
    "    tuner.search(X_train_scaled, y_train, epochs=SEARCH_FIT_EPOCHS, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "    print(f\"Best Hyper Values: {best_hyper.values}\")\n",
    "    \n",
    "    nn = tuner.get_best_models(1)[0]\n",
    "    eval_results = nn.evaluate(X_test_scaled, y_test, verbose=2, batch_size=BATCH_SIZE )\n",
    "    print(f\"Best Model Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")\n",
    "\n",
    "    nn.save(\"./saved_models/tuned.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71ca9b-9cc3-4c85-9dab-e4b7d969ca52",
   "metadata": {},
   "source": [
    "# Model Reload /Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0fdee2d-2e95-4fb1-96e9-c428546102cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building new model\n",
      "Input shape: (None, 1, 512), Output shape: (None, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733098318.268750   46453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733098318.310272   46453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733098318.310320   46453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733098318.316823   46453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733098318.316885   46453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733098318.316903   46453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733098319.294944   46453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733098319.295049   46453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-01 16:11:59.295060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1733098319.295112   46453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-01 16:11:59.295137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5363 MB memory:  -> device: 0, name: NVIDIA RTX 2000 Ada Generation Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ A_LSTM_tanh_sigmoid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Modulo_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ A_LSTM_tanh_sigmoid (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m69,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Modulo_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,793</span> (272.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,793\u001b[0m (272.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,793</span> (272.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,793\u001b[0m (272.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "if BUILD_NETWORK:\n",
    "    print(\"Building new model\")\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    input_shape = (None, 1, CHUNK_SIZE)\n",
    "    nn.add(tf.keras.Input(shape=input_shape[1:], name=\"Input_Layer\"))\n",
    "\n",
    "    activation_A = \"tanh\"\n",
    "    recurrent_activation_A = \"sigmoid\"\n",
    "    nn.add(tf.keras.layers.LSTM(\n",
    "        PROCESSING_UNITS, return_sequences=True, activation=activation_A, recurrent_activation=recurrent_activation_A,\n",
    "        name=f\"A_LSTM_{activation_A}_{recurrent_activation_A}\"))\n",
    "\n",
    "    nn.add(tf.keras.layers.Dense(units = OUTPUT_SIZE, activation=modulo_output, name='Modulo_Layer'))\n",
    "\n",
    "# Check the structure of the model\n",
    "print(f\"Input shape: {nn.input_shape}, Output shape: {nn.output_shape}\")\n",
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c6ff4-2ca0-4ac0-af80-7d48b157675a",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08319c4f-7080-477b-93b8-eca4791c449a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ A_LSTM_tanh_sigmoid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Modulo_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ A_LSTM_tanh_sigmoid (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m69,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Modulo_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,793</span> (272.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,793\u001b[0m (272.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,793</span> (272.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,793\u001b[0m (272.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Training model\n",
      "Epoch 1/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 16:12:00.753616: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.5589 - modulo_distance_accuracy: 0.4882 - modulo_rounded_accuracy: 0.0637\n",
      "Epoch 1: modulo_distance_accuracy improved from -inf to 0.52243, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 34ms/step - loss: 2.5577 - modulo_distance_accuracy: 0.4885 - modulo_rounded_accuracy: 0.0639\n",
      "Epoch 2/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.9777 - modulo_distance_accuracy: 0.6045 - modulo_rounded_accuracy: 0.1426\n",
      "Epoch 2: modulo_distance_accuracy improved from 0.52243 to 0.65680, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 1.9768 - modulo_distance_accuracy: 0.6046 - modulo_rounded_accuracy: 0.1427\n",
      "Epoch 3/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4643 - modulo_distance_accuracy: 0.7071 - modulo_rounded_accuracy: 0.2381\n",
      "Epoch 3: modulo_distance_accuracy improved from 0.65680 to 0.70725, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 1.4643 - modulo_distance_accuracy: 0.7071 - modulo_rounded_accuracy: 0.2381\n",
      "Epoch 4/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4596 - modulo_distance_accuracy: 0.7081 - modulo_rounded_accuracy: 0.2430\n",
      "Epoch 4: modulo_distance_accuracy improved from 0.70725 to 0.70900, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - loss: 1.4596 - modulo_distance_accuracy: 0.7081 - modulo_rounded_accuracy: 0.2430\n",
      "Epoch 5/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.4588 - modulo_distance_accuracy: 0.7082 - modulo_rounded_accuracy: 0.2409\n",
      "Epoch 5: modulo_distance_accuracy did not improve from 0.70900\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - loss: 1.4588 - modulo_distance_accuracy: 0.7082 - modulo_rounded_accuracy: 0.2409\n",
      "Epoch 6/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.4513 - modulo_distance_accuracy: 0.7097 - modulo_rounded_accuracy: 0.2416\n",
      "Epoch 6: modulo_distance_accuracy improved from 0.70900 to 0.71143, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 1.4513 - modulo_distance_accuracy: 0.7097 - modulo_rounded_accuracy: 0.2416\n",
      "Epoch 7/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.4301 - modulo_distance_accuracy: 0.7140 - modulo_rounded_accuracy: 0.2482\n",
      "Epoch 7: modulo_distance_accuracy improved from 0.71143 to 0.71299, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 1.4301 - modulo_distance_accuracy: 0.7140 - modulo_rounded_accuracy: 0.2482\n",
      "Epoch 8/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.4268 - modulo_distance_accuracy: 0.7146 - modulo_rounded_accuracy: 0.2489\n",
      "Epoch 8: modulo_distance_accuracy improved from 0.71299 to 0.71872, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - loss: 1.4268 - modulo_distance_accuracy: 0.7146 - modulo_rounded_accuracy: 0.2489\n",
      "Epoch 9/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.3207 - modulo_distance_accuracy: 0.7359 - modulo_rounded_accuracy: 0.2861\n",
      "Epoch 9: modulo_distance_accuracy improved from 0.71872 to 0.73542, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 1.3207 - modulo_distance_accuracy: 0.7359 - modulo_rounded_accuracy: 0.2861\n",
      "Epoch 10/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.2975 - modulo_distance_accuracy: 0.7405 - modulo_rounded_accuracy: 0.2918\n",
      "Epoch 10: modulo_distance_accuracy improved from 0.73542 to 0.74580, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 1.2973 - modulo_distance_accuracy: 0.7405 - modulo_rounded_accuracy: 0.2919\n",
      "Epoch 11/33\n",
      "\u001b[1m260/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.2970 - modulo_distance_accuracy: 0.7406 - modulo_rounded_accuracy: 0.2944\n",
      "Epoch 11: modulo_distance_accuracy improved from 0.74580 to 0.74607, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 1.2949 - modulo_distance_accuracy: 0.7410 - modulo_rounded_accuracy: 0.2949\n",
      "Epoch 12/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.2809 - modulo_distance_accuracy: 0.7438 - modulo_rounded_accuracy: 0.2958\n",
      "Epoch 12: modulo_distance_accuracy did not improve from 0.74607\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 1.2811 - modulo_distance_accuracy: 0.7438 - modulo_rounded_accuracy: 0.2958\n",
      "Epoch 13/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2228 - modulo_distance_accuracy: 0.7554 - modulo_rounded_accuracy: 0.3096\n",
      "Epoch 13: modulo_distance_accuracy improved from 0.74607 to 0.75713, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - loss: 1.2228 - modulo_distance_accuracy: 0.7554 - modulo_rounded_accuracy: 0.3096\n",
      "Epoch 14/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.1923 - modulo_distance_accuracy: 0.7615 - modulo_rounded_accuracy: 0.3194\n",
      "Epoch 14: modulo_distance_accuracy did not improve from 0.75713\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 1.1925 - modulo_distance_accuracy: 0.7615 - modulo_rounded_accuracy: 0.3194\n",
      "Epoch 15/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.3549 - modulo_distance_accuracy: 0.7290 - modulo_rounded_accuracy: 0.2652\n",
      "Epoch 15: modulo_distance_accuracy did not improve from 0.75713\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - loss: 1.3546 - modulo_distance_accuracy: 0.7291 - modulo_rounded_accuracy: 0.2653\n",
      "Epoch 16/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.1444 - modulo_distance_accuracy: 0.7711 - modulo_rounded_accuracy: 0.3295\n",
      "Epoch 16: modulo_distance_accuracy improved from 0.75713 to 0.76619, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 1.1445 - modulo_distance_accuracy: 0.7711 - modulo_rounded_accuracy: 0.3295\n",
      "Epoch 17/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.3767 - modulo_distance_accuracy: 0.7247 - modulo_rounded_accuracy: 0.2671\n",
      "Epoch 17: modulo_distance_accuracy did not improve from 0.76619\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 1.3757 - modulo_distance_accuracy: 0.7249 - modulo_rounded_accuracy: 0.2673\n",
      "Epoch 18/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.1747 - modulo_distance_accuracy: 0.7651 - modulo_rounded_accuracy: 0.3174\n",
      "Epoch 18: modulo_distance_accuracy improved from 0.76619 to 0.76999, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 1.1745 - modulo_distance_accuracy: 0.7651 - modulo_rounded_accuracy: 0.3174\n",
      "Epoch 19/33\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.1142 - modulo_distance_accuracy: 0.7772 - modulo_rounded_accuracy: 0.3329\n",
      "Epoch 19: modulo_distance_accuracy improved from 0.76999 to 0.77542, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - loss: 1.1143 - modulo_distance_accuracy: 0.7771 - modulo_rounded_accuracy: 0.3329\n",
      "Epoch 20/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.1083 - modulo_distance_accuracy: 0.7783 - modulo_rounded_accuracy: 0.3341\n",
      "Epoch 20: modulo_distance_accuracy improved from 0.77542 to 0.77985, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 1.1082 - modulo_distance_accuracy: 0.7784 - modulo_rounded_accuracy: 0.3341\n",
      "Epoch 21/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.1424 - modulo_distance_accuracy: 0.7715 - modulo_rounded_accuracy: 0.3235\n",
      "Epoch 21: modulo_distance_accuracy did not improve from 0.77985\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 1.1423 - modulo_distance_accuracy: 0.7715 - modulo_rounded_accuracy: 0.3235\n",
      "Epoch 22/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.2583 - modulo_distance_accuracy: 0.7483 - modulo_rounded_accuracy: 0.3006\n",
      "Epoch 22: modulo_distance_accuracy did not improve from 0.77985\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - loss: 1.2582 - modulo_distance_accuracy: 0.7484 - modulo_rounded_accuracy: 0.3006\n",
      "Epoch 23/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.0799 - modulo_distance_accuracy: 0.7840 - modulo_rounded_accuracy: 0.3388\n",
      "Epoch 23: modulo_distance_accuracy improved from 0.77985 to 0.78517, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 1.0798 - modulo_distance_accuracy: 0.7840 - modulo_rounded_accuracy: 0.3388\n",
      "Epoch 24/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0678 - modulo_distance_accuracy: 0.7864 - modulo_rounded_accuracy: 0.3404\n",
      "Epoch 24: modulo_distance_accuracy improved from 0.78517 to 0.78528, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 1.0679 - modulo_distance_accuracy: 0.7864 - modulo_rounded_accuracy: 0.3404\n",
      "Epoch 25/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.0322 - modulo_distance_accuracy: 0.7936 - modulo_rounded_accuracy: 0.3372\n",
      "Epoch 25: modulo_distance_accuracy improved from 0.78528 to 0.79726, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 1.0321 - modulo_distance_accuracy: 0.7936 - modulo_rounded_accuracy: 0.3372\n",
      "Epoch 26/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9775 - modulo_distance_accuracy: 0.8045 - modulo_rounded_accuracy: 0.3502\n",
      "Epoch 26: modulo_distance_accuracy improved from 0.79726 to 0.80589, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - loss: 0.9775 - modulo_distance_accuracy: 0.8045 - modulo_rounded_accuracy: 0.3502\n",
      "Epoch 27/33\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.9544 - modulo_distance_accuracy: 0.8091 - modulo_rounded_accuracy: 0.3592\n",
      "Epoch 27: modulo_distance_accuracy improved from 0.80589 to 0.81074, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - loss: 0.9542 - modulo_distance_accuracy: 0.8092 - modulo_rounded_accuracy: 0.3593\n",
      "Epoch 28/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.9616 - modulo_distance_accuracy: 0.8077 - modulo_rounded_accuracy: 0.3486\n",
      "Epoch 28: modulo_distance_accuracy did not improve from 0.81074\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - loss: 0.9615 - modulo_distance_accuracy: 0.8077 - modulo_rounded_accuracy: 0.3486\n",
      "Epoch 29/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9169 - modulo_distance_accuracy: 0.8166 - modulo_rounded_accuracy: 0.3649\n",
      "Epoch 29: modulo_distance_accuracy improved from 0.81074 to 0.81803, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - loss: 0.9169 - modulo_distance_accuracy: 0.8166 - modulo_rounded_accuracy: 0.3649\n",
      "Epoch 30/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.8925 - modulo_distance_accuracy: 0.8215 - modulo_rounded_accuracy: 0.3707\n",
      "Epoch 30: modulo_distance_accuracy improved from 0.81803 to 0.82260, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - loss: 0.8925 - modulo_distance_accuracy: 0.8215 - modulo_rounded_accuracy: 0.3707\n",
      "Epoch 31/33\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.8713 - modulo_distance_accuracy: 0.8257 - modulo_rounded_accuracy: 0.3765\n",
      "Epoch 31: modulo_distance_accuracy did not improve from 0.82260\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.8715 - modulo_distance_accuracy: 0.8257 - modulo_rounded_accuracy: 0.3764\n",
      "Epoch 32/33\n",
      "\u001b[1m270/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.9222 - modulo_distance_accuracy: 0.8156 - modulo_rounded_accuracy: 0.3695\n",
      "Epoch 32: modulo_distance_accuracy improved from 0.82260 to 0.82738, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - loss: 0.9195 - modulo_distance_accuracy: 0.8161 - modulo_rounded_accuracy: 0.3708\n",
      "Epoch 33/33\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.8155 - modulo_distance_accuracy: 0.8369 - modulo_rounded_accuracy: 0.4264\n",
      "Epoch 33: modulo_distance_accuracy improved from 0.82738 to 0.83619, saving model to ./saved_models/best.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - loss: 0.8155 - modulo_distance_accuracy: 0.8369 - modulo_rounded_accuracy: 0.4264\n",
      "Input shape: (None, 1, 512), Output shape: (None, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ A_LSTM_tanh_sigmoid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Modulo_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ A_LSTM_tanh_sigmoid (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │        \u001b[38;5;34m69,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Modulo_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">209,381</span> (817.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m209,381\u001b[0m (817.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,793</span> (272.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,793\u001b[0m (272.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,588</span> (545.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m139,588\u001b[0m (545.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Reset the \"best\" score and set up a callback to save the model as it improves during training.\n",
    "# If you're manually training iteratively, comment this out to preserve the best-ness:\n",
    "model_checkpoint_callback = initialize_save_best(BEST_PATH)\n",
    "\n",
    "# It can be helpful to load the best, train some more, and try to improve it:\n",
    "if LOAD_BEST_MODEL:\n",
    "    if os.path.exists(BEST_PATH):\n",
    "        print(f\"Loading model from {BEST_PATH}\")\n",
    "        nn = tf.keras.models.load_model(BEST_PATH,\n",
    "            custom_objects={\n",
    "                'modulo_distance_loss': modulo_distance_loss,\n",
    "                'modulo_distance_accuracy': modulo_distance_accuracy,\n",
    "                'modulo_rounded_accuracy': modulo_rounded_accuracy,\n",
    "                'modulo_output': modulo_output\n",
    "        })\n",
    "\n",
    "# Train the model\n",
    "if TRAIN_MODEL:\n",
    "    # Decide what metrics to use\n",
    "    if USE_CUSTOM_METRICS:\n",
    "        loss = modulo_distance_loss\n",
    "        metrics = [modulo_distance_accuracy, modulo_rounded_accuracy]\n",
    "    else:\n",
    "        loss = LOSS_METRIC\n",
    "        metrics = [MAIN_ACCURACY_METRIC]\n",
    "\n",
    "    print(nn.summary())\n",
    "    print(f\"Training model\")\n",
    "    \n",
    "    if SAVE_BEST_MODEL:\n",
    "        callbacks = [model_checkpoint_callback]\n",
    "    else:\n",
    "        callbacks = None\n",
    "    \n",
    "    # Compile the Sequential model together and customize metrics\n",
    "    nn.compile(loss=loss, optimizer=OPTIMIZER, metrics=metrics)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    fit_model = nn.fit(X_train_scaled, y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Input shape: {nn.input_shape}, Output shape: {nn.output_shape}\")\n",
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347990dc-230b-460f-852d-c2e0e81cef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using training data as input; results are not valid for accuracy but may be informative about function\n",
      "Input: (1000, 512, 1), Expected: (1000, 1, 1)\n",
      "Input: (1, 512, 1), Expected: (1, 1, 1), [[[7.]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "raw_predicted: (1, 512, 1)\n",
      "predicted: (1,)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "# Predicting the whole test set can take a lot of memory, so this can be used to limit it:\n",
    "TEST_SET_SIZE = X_test_scaled.shape[0]\n",
    "MAX_TEST_SUBSET = 1000\n",
    "TEST_SUBSET_SIZE = min(TEST_SET_SIZE, MAX_TEST_SUBSET) if MAX_TEST_SUBSET > 0 else TEST_SET_SIZE\n",
    "X_test_scaled_subset = X_test_scaled[0:TEST_SUBSET_SIZE, :, :]\n",
    "y_test_subset = y_test[0:TEST_SUBSET_SIZE, :, :]\n",
    "\n",
    "# Sometimes for troubleshooting I want to use the training set, which should produce more accurate predictions:\n",
    "TRAIN_SET_SIZE = X_train_scaled.shape[0]\n",
    "MAX_TRAIN_SUBSET = MAX_TEST_SUBSET\n",
    "TRAIN_SUBSET_SIZE = min(TRAIN_SET_SIZE, MAX_TRAIN_SUBSET) if MAX_TRAIN_SUBSET > 0 else TRAIN_SET_SIZE\n",
    "X_train_scaled_subset = X_train_scaled[0:TRAIN_SUBSET_SIZE, :, :]\n",
    "y_train_subset = y_train[0:TRAIN_SUBSET_SIZE, :, :]\n",
    "\n",
    "use_training_data = True\n",
    "if use_training_data:\n",
    "    print(\"Using training data as input; results are not valid for accuracy but may be informative about function\")\n",
    "    input = X_train_scaled_subset\n",
    "    expected = y_train_subset\n",
    "else:\n",
    "    print(\"Using test data as input\")\n",
    "    input = X_test_scaled_subset\n",
    "    expected = y_test_subset\n",
    "\n",
    "# Where is the key!>?!?!?!???\n",
    "# Input: (1000, 512, 1), Expected: (1000, 1, 1)\n",
    "# Setting up to do just one input...\n",
    "which_one = 420\n",
    "print(f\"Input: {input.shape}, Expected: {expected.shape}\")\n",
    "input = input[which_one:which_one+1, :, :]\n",
    "expected = expected[which_one:which_one+1, :, :]\n",
    "print(f\"Input: {input.shape}, Expected: {expected.shape}, {expected}\")\n",
    "\n",
    "# Trying to figure out where to actually get the keys...    \n",
    "if INFER_KEY:\n",
    "    if False:\n",
    "        # Check key accuracy...    \n",
    "        checks_to_do = 100\n",
    "        for r in range(checks_to_do):\n",
    "            which_one = random.randint(0, input.shape[0]-1)\n",
    "            c_offsets_scaled = input[which_one,:,0]\n",
    "            c_offsets = X_scaler.inverse_transform([c_offsets_scaled])[0,:].round().astype(int)\n",
    "            c_str = encoders.offsets_to_string(c_offsets)\n",
    "            k_float = expected[which_one, 0, 0]\n",
    "            k = int(round(k_float))\n",
    "            p = encoders.decode_caesar(c_str, k)\n",
    "            check_in_plaintext(p)\n",
    "\n",
    "    # Look for a good key in the output\n",
    "    raw_predicted = nn.predict(input, batch_size=BATCH_SIZE)\n",
    "    print(f\"raw_predicted: {raw_predicted.shape}\")\n",
    "    predicted = raw_predicted[:, 0, 0].astype(np.float64)\n",
    "    print(f\"predicted: {predicted.shape}\")\n",
    "    \n",
    "    offsets = range(0, CHUNK_SIZE)\n",
    "    #offsets = [0, CHUNK_SIZE//2, CHUNK_SIZE-1]\n",
    "    \n",
    "    col_offset = []\n",
    "    col_values = []\n",
    "    col_loss = []\n",
    "    col_acc_dist = []\n",
    "    col_acc_round = []\n",
    "    \n",
    "    for offset in offsets:\n",
    "        predicted = raw_predicted[:, offset, 0].astype(np.float64)\n",
    "        loss = modulo_distance_loss(expected, predicted)\n",
    "        accuracy_distance = modulo_distance_accuracy(expected, predicted)\n",
    "        accuracy_rounded = modulo_rounded_accuracy(expected, predicted)\n",
    "\n",
    "        col_offset.append(offset)\n",
    "        col_loss.append(loss.numpy())\n",
    "        col_values.append(predicted[0])\n",
    "        col_acc_dist.append(accuracy_distance.numpy())\n",
    "        col_acc_round.append(accuracy_rounded.numpy())\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Offset\": col_offset,\n",
    "        \"Loss\": col_loss,\n",
    "        \"Values\": col_values,\n",
    "        \"Accuracy (Distance)\": col_acc_dist,\n",
    "        \"Accuracy (Rounded)\": col_acc_round \n",
    "    }).set_index(\"Offset\")\n",
    "    print(metrics_df.describe())\n",
    "    metrics_df.plot()\n",
    "\n",
    "if False:\n",
    "    if USE_CUSTOM_METRICS:\n",
    "        print(\"Evaluating with model.predict() ...\")    \n",
    "        raw_predicted = nn.predict(input, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        print(f\"raw_predicted: {raw_predicted.shape}\")\n",
    "        if INFER_KEY:\n",
    "            # Average together all the predictions\n",
    "            #!!! Not confident here\n",
    "            #y_pred = np.array([np.mean(raw_predicted[x,:,:]) for x in range(raw_predicted.shape[0])]).astype(np.float64)\n",
    "            y_pred = raw_predicted[:, CHUNK_SIZE-1, 0].astype(np.float64)\n",
    "        else:\n",
    "            # This is probably wrong...\n",
    "            y_pred = raw_predicted[:,1,:]\n",
    "        print(f\"y_pred: {y_pred.shape}\")\n",
    "    \n",
    "        # My custom loss and accuracy functions are running out of memory for decoded texts for some reason...\n",
    "        if INFER_KEY:\n",
    "            loss = modulo_distance_loss(expected, y_pred)\n",
    "            accuracy_distance = modulo_distance_accuracy(expected, y_pred)\n",
    "            accuracy_rounded = modulo_rounded_accuracy(expected, y_pred)\n",
    "            print(f\"Calling Functions Loss: {loss:0.6}, Accuracy (Distance): {accuracy_distance:0.6}, Accuracy (Rounded): {accuracy_rounded:0.6}\")\n",
    "    \n",
    "        if INFER_KEY and False:\n",
    "            print(f\"y_pred: {y_pred.shape}, expected: {expected.shape}\")\n",
    "            pred_pd = pd.DataFrame(y_pred)\n",
    "            true_pd = pd.DataFrame(expected[:,0,0])\n",
    "            print(\"Inferred key distribution:\\n\", pred_pd.describe())\n",
    "            print(\"Inferred key value counts:\\n\", pred_pd[0].round().value_counts())\n",
    "            print(\"True key distribution    :\\n\", true_pd.describe())\n",
    "            print(\"True key value counts    :\\n\", true_pd[0].round().value_counts())\n",
    "    \n",
    "    # I don't think evaluate() is handling the plethora of keys output by the model. These metrics are probably quite wrong:\n",
    "    print(\"Evaluating with model.evaluate() ...\")\n",
    "    eval_results = nn.evaluate(X_test_scaled_subset, y_test_subset, batch_size=BATCH_SIZE)\n",
    "    print(f\"Test Set        : Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")\n",
    "    eval_results = nn.evaluate(X_train_scaled_subset, y_train_subset, batch_size=BATCH_SIZE)\n",
    "    print(f\"Training Set    : Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")    \n",
    "    eval_results = nn.evaluate(input, expected, batch_size=BATCH_SIZE)\n",
    "    print(f\"Whichever Set   : Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488ae3d-b10f-40d7-826a-61fedba4cb2b",
   "metadata": {},
   "source": [
    "# Model Usefulness Spot-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4abd4fd4-831e-43a5-9351-c0c2cfa1be2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Key:  9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Inferred Key:  2.6089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "                  0\n",
      "count  10240.000000\n",
      "mean       2.608900\n",
      "std        0.050282\n",
      "min        1.421931\n",
      "25%        2.592635\n",
      "50%        2.605671\n",
      "75%        2.627169\n",
      "max        2.789152 0\n",
      "3.0    10200\n",
      "2.0       37\n",
      "1.0        3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# These functions assume Caesar cipher, and need to be updated after shape change\n",
    "\n",
    "def decode_chunks_with_model(chunks: list[list], model, scaler, input_already_scaled = True) -> list[list]:\n",
    "    if input_already_scaled:\n",
    "        return model.predict(chunks)\n",
    "    else:\n",
    "        return model.predict(scaler.transform(chunks))\n",
    "\n",
    "def decode_text_with_model(ciphertext: str, model, scaler) -> str:\n",
    "    offset_chunks = helpers.chunkify(encoders.string_to_offsets(ciphertext), CHUNK_SIZE)\n",
    "    decoded_chunks = decode_chunks_with_model(offset_chunks, model, scaler, input_already_scaled = False)\n",
    "    rounded = np.rint(decoded_chunks.flatten()).astype(int)\n",
    "    return encoders.offsets_to_string(rounded)\n",
    "\n",
    "def infer_key_with_model(ciphertext: str, model, scaler) -> int:\n",
    "    chunks = helpers.string_to_bytes(ciphertext, CHUNK_SIZE)    \n",
    "    scaled_chunks = scaler.transform(chunks)\n",
    "    tmp_x = np.array(scaled_chunks).reshape((-1, CHUNK_SIZE, 1))\n",
    "    keys = model.predict(tmp_x)\n",
    "    key = np.mean(keys)\n",
    "    return key\n",
    "\n",
    "if INFER_TEXT:    \n",
    "    CHUNKS_TO_CHECK = 2\n",
    "else:\n",
    "    CHUNKS_TO_CHECK = 20\n",
    "\n",
    "cipher_file_db = sid_to_c[list(sid_to_c.keys())[0]][0]\n",
    "ciphertext_path = cipher_file_db.path\n",
    "ciphertext = helpers.read_text_file(ciphertext_path)\n",
    "ciphertext = ciphertext[0:CHUNK_SIZE * CHUNKS_TO_CHECK]\n",
    "\n",
    "if INFER_TEXT:    \n",
    "    print(\"Decoded   : \", decode_text_with_model(ciphertext, nn, X_scaler))\n",
    "if INFER_KEY:\n",
    "    with db.get_session() as session:\n",
    "        correct_key = db.get_key_by_id(session, cipher_file_db.key_id).value\n",
    "    print(\"Correct Key: \", correct_key)\n",
    "    \n",
    "    inferred_key = infer_key_with_model(ciphertext, nn, X_scaler)\n",
    "    print(\"Inferred Key: \", inferred_key)\n",
    "    \n",
    "    chunks = helpers.string_to_bytes(ciphertext, CHUNK_SIZE)\n",
    "    scaled_chunks = scaler.transform(chunks)\n",
    "    pred = nn.predict(scaled_chunks.reshape((-1, CHUNK_SIZE, 1)))\n",
    "\n",
    "    pred_df = pd.DataFrame(pred.flatten())\n",
    "    print(pred_df.describe(), pred_df[0].round().value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
