{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bca2471e-572c-4233-b18c-e8e03e8cf40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import pathlib\n",
    "\n",
    "from credentials import SAMPLE_DB, FULL_DB\n",
    "from librarian import SAMPLE_DATA_DIR\n",
    "\n",
    "import encoders\n",
    "import db_connect\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9bdcd65-ceca-4b1a-921a-4544e38b37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = SAMPLE_DATA_DIR\n",
    "CHUNK_SIZE = 4096\n",
    "\n",
    "ENCRYPTED_FILE_LIMIT = 2 # -1 to disable limit\n",
    "SPLIT_SEED = 42\n",
    "SPLIT_TEST_SIZE = 0.25     # 0.25 is default\n",
    "\n",
    "db = db_connect.DB(SAMPLE_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "789ab2e5-5e11-4812-91be-bb9a63acb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder IDs: {'None': 1, 'Simplifier': 2, 'Caesar Cipher': 3, 'Substitution Cipher': 4, 'Enigma Machine': 5}\n",
      "Key Type IDs: {'Character Offset': 1, 'Character Map': 2, 'Rotor Settings': 3}\n"
     ]
    }
   ],
   "source": [
    "# Get database IDs for encoders and key types\n",
    "\n",
    "encoder_ids= {}\n",
    "key_type_ids = {}\n",
    "\n",
    "with db.get_session() as session:\n",
    "    for encoder in encoders.ALL_ENCODER_NAMES:\n",
    "        id = db.get_encoder_id(session, encoder)\n",
    "        encoder_ids[encoder] = id\n",
    "\n",
    "    print(f\"Encoder IDs: {encoder_ids}\")\n",
    "\n",
    "    for key_type in encoders.KEY_NAMES:\n",
    "        id = db.get_key_type_id(session, key_type)\n",
    "        key_type_ids[key_type] = id\n",
    "\n",
    "    print(f\"Key Type IDs: {key_type_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fc8e5ca-4b37-4947-9e79-f061cc993a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map source ID to plaintext file (1) details, and source ID to corresponding ciphertext files (1+) details\n",
    "sid_to_p = {}\n",
    "sid_to_c = {}\n",
    "\n",
    "cipher_id = encoder_ids[encoders.ENCODER_CAESAR]\n",
    "with db.get_session() as session:\n",
    "    # Get all files encrypted with the cipher we care about\n",
    "    encrypted_files = db.get_files_by_source_and_encoder(session, -1, cipher_id)\n",
    "\n",
    "    if len(encrypted_files) > ENCRYPTED_FILE_LIMIT and ENCRYPTED_FILE_LIMIT > 0:\n",
    "        encrypted_files = encrypted_files[0:ENCRYPTED_FILE_LIMIT]\n",
    "\n",
    "    for c in encrypted_files:\n",
    "        sid = c.source_id\n",
    "    \n",
    "        if sid not in sid_to_p:\n",
    "            plaintext_ids = db.get_files_by_source_and_encoder(session, sid, encoder_ids[encoders.ENCODER_SIMPLIFIER])\n",
    "            if len(plaintext_ids) != 1:\n",
    "                raise Exception(f\"Found {len(plaintext_ids)} plaintexts for source ID {sid}; should be exactly 1\")\n",
    "            sid_to_p[sid] = plaintext_ids[0]\n",
    "\n",
    "        if sid not in sid_to_c:\n",
    "            sid_to_c[sid] = []\n",
    "        sid_to_c[sid].append(c)\n",
    "\n",
    "len(sid_to_p), len(sid_to_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93dacf19-4c10-4663-b411-a670ae9704a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([65]),\n",
       "  array([66]),\n",
       "  array([67]),\n",
       "  array([68]),\n",
       "  array([69]),\n",
       "  array([70]),\n",
       "  array([71])],\n",
       " [array([65, 66]), array([67, 68]), array([69, 70]), array([70, 71])],\n",
       " [array([65, 66, 67, 68, 69, 70]), array([66, 67, 68, 69, 70, 71])],\n",
       " [array([65, 66, 67, 68, 69, 70, 71])])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a string to a list of lists of numbers, broken up into chunks.\n",
    "# If the length is not evenly divisible by chunk_size, the final chunk\n",
    "# will overlap the previous one so the whole string gets converted.\n",
    "def string_to_bytes(text, chunk_size) -> [[]]:\n",
    "    if len(text) < chunk_size:\n",
    "        raise Exception(f\"Chunk size ({chunk_size}) must be no greater than text length ({len(text)})\")\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    offset = 0\n",
    "    while offset < len(text):\n",
    "        if (offset + chunk_size >= len(text)):\n",
    "            offset = len(text) - chunk_size\n",
    "        \n",
    "        # I'm sure there is a more optimal way to do this...\n",
    "        encoded = text[offset : offset + chunk_size].encode('UTF-8')\n",
    "        numbered = np.array([b for b in encoded])\n",
    "\n",
    "        if len(encoded) != chunk_size or len(numbered) != chunk_size:\n",
    "            raise Exception(f\"Conversion chunk size error: {len(text)}, {len(encoded)}, {len(numbered)}, {chunk_size}\")\n",
    "        chunks.append(numbered)\n",
    "\n",
    "        offset += chunk_size     \n",
    "        \n",
    "    return chunks\n",
    "\n",
    "# Simple test cases\n",
    "string_to_bytes(\"ABCDEFG\", 1), string_to_bytes(\"ABCDEFG\", 2), string_to_bytes(\"ABCDEFG\", 6), string_to_bytes(\"ABCDEFG\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3f6de1c-79f8-4637-8dec-ade266665517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1818, 4096), (1818, 4096), (4096,), (4096,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build up the features (X, the cipher texts as values) and targets (y, the plain texts as values).\n",
    "# Note the targets can be repeated since a plaintext can be encrypted repeatedly by different keys.\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for sid in sid_to_p:\n",
    "    plaintext = helpers.read_text_file(os.path.normpath(sid_to_p[sid].path))\n",
    "    target_chunks = string_to_bytes(plaintext, CHUNK_SIZE)\n",
    "\n",
    "    for c in sid_to_c[sid]:\n",
    "        ciphertext = helpers.read_text_file(os.path.normpath(c.path))\n",
    "        feature_chunks = string_to_bytes(ciphertext, CHUNK_SIZE)\n",
    "\n",
    "        if len(target_chunks) != len(feature_chunks):\n",
    "            raise Exception(f\"Chunk count mismatch; {len(target_chunks)} != {len(feature_chunks)}\")\n",
    "\n",
    "        for i in range (len(target_chunks)):\n",
    "            X.append(feature_chunks[i])\n",
    "            y.append(target_chunks[i])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X.shape, y.shape, X[0].shape, y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e55451fa-ee72-4835-b18a-d03d44899412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1818 1818 1363 455 1363 455\n"
     ]
    }
   ],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=SPLIT_TEST_SIZE, random_state=SPLIT_SEED)\n",
    "print( len(X), len(y), len(X_train), len(X_test), len(y_train), len(y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d5fd198-2be6-4f66-91ff-0bbb1ccb819f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1363, 4096), (455, 4096))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0fdee2d-2e95-4fb1-96e9-c428546102cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732074710.742625     419 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732074710.882879     419 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732074710.882938     419 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732074710.885789     419 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732074710.885831     419 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732074710.885851     419 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732074712.442801     419 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732074712.442958     419 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-19 19:51:52.442975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1732074712.443052     419 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-19 19:51:52.443076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5363 MB memory:  -> device: 0, name: NVIDIA RTX 2000 Ada Generation Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">33,562,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">67,117,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">67,117,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">67,117,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">67,117,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">33,558,528</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │    \u001b[38;5;34m33,562,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │    \u001b[38;5;34m67,117,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │    \u001b[38;5;34m67,117,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │    \u001b[38;5;34m67,117,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │    \u001b[38;5;34m67,117,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m33,558,528\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">335,589,376</span> (1.25 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m335,589,376\u001b[0m (1.25 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">335,589,376</span> (1.25 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m335,589,376\u001b[0m (1.25 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "in_shape = (CHUNK_SIZE,)\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "nn.add(tf.keras.Input(shape=in_shape))\n",
    "\n",
    "# Hidden layers\n",
    "activations = [\"tanh\", \"relu\", \"selu\", \"elu\", \"exponential\"]\n",
    "unit_counts = [CHUNK_SIZE*2]\n",
    "for u in unit_counts:\n",
    "    for a in activations:\n",
    "        nn.add(tf.keras.layers.Dense(units=u, activation=a))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=CHUNK_SIZE))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08319c4f-7080-477b-93b8-eca4791c449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732074713.846390     773 service.cc:146] XLA service 0x7f27e8017c20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732074713.846441     773 service.cc:154]   StreamExecutor device (0): NVIDIA RTX 2000 Ada Generation Laptop GPU, Compute Capability 8.9\n",
      "2024-11-19 19:51:53.905462: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-19 19:51:54.029461: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n",
      "2024-11-19 19:51:55.148193: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_89', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:55.395401: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_385', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:55.564762: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_103', 132 bytes spill stores, 132 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:55.569435: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_289', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:55.667972: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_393', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:55.893599: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_103', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:55.989292: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_153', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:55.995127: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_393', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:56.050807: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_89', 180 bytes spill stores, 180 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:56.349593: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_393', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:56.490491: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_289', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:56.555637: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_393', 36 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:56.654147: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_393', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:56.928136: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_387', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:56.978263: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_289', 276 bytes spill stores, 276 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:56.980337: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_289', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:57.130661: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_387', 36 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:57.176171: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_385', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:57.188894: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_385', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-11-19 19:51:57.368656: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_153', 180 bytes spill stores, 180 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/43\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: nan - mae: nan                                                   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732074721.557613     773 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: nan - mae: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 19:52:08.052959: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_103', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:08.071949: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_153', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:08.476588: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_103', 204 bytes spill stores, 204 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:08.617051: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_89', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:08.645072: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_153', 204 bytes spill stores, 204 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:09.664262: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_289', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:10.481723: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_385', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:10.718936: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_289', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:11.475807: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_89', 92 bytes spill stores, 92 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:11.602775: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_289', 348 bytes spill stores, 348 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:11.754494: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_153', 84 bytes spill stores, 84 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:11.833113: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_289', 104 bytes spill stores, 104 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:12.360864: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_387', 36 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:12.744749: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_393', 36 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:12.761143: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_393', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:13.910930: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_387', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:14.063866: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_385', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-11-19 19:52:14.164476: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_385', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 357ms/step - loss: nan - mae: nan\n",
      "Epoch 2/3\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: nan - mae: nan\n",
      "Epoch 3/3\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: nan - mae: nan\n",
      "15/15 - 6s - 379ms/step - loss: nan - mae: nan\n",
      "Loss: nan, Accuracy: nan\n"
     ]
    }
   ],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
    "\n",
    "# Fit the model to the training data\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=3)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
