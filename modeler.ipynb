{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257e4334-a266-4af7-8a69-d2268f65d0e7",
   "metadata": {},
   "source": [
    "# Modeler\n",
    "\n",
    "This notebook is meant to be used interactively, to create models for breaking codes. It assumes you have already used the Librarian script to populate your filesystem and database.\n",
    "\n",
    "## How to Use This File\n",
    "\n",
    "Make sure you have populated your database and created credentials.py.\n",
    "\n",
    "After configuration, the first several cells deal with reading, scaling, splitting, and shaping the data. You shouldn't need to adjust much here unless you change the data shape.\n",
    "\n",
    "The cells related to Tuning, Building, and Training the network are meant for lots of manual experimentation. Be very conscious of data shape -- that's the topic that caused me the most trouble.\n",
    "\n",
    "The last several cells are related to evaluating the model. Metrics reported from Tensorflow can be very misleading (presumably because I'm not using them right) so I have other checks in place. This is a good section in which to experiment with the models you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2471e-572c-4233-b18c-e8e03e8cf40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "# Disable some chatty warnings from Tensorflow:\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from credentials import CONNECTION_INFO\n",
    "from constants import *\n",
    "from crackers import Caesar_Cracker\n",
    "\n",
    "import encoders\n",
    "import db_connect\n",
    "import helpers\n",
    "import tf_helpers\n",
    "import models\n",
    "\n",
    "# Callbacks for use with TensorFlow\n",
    "from tf_helpers import modulo_output, modulo_distance_loss, modulo_distance_accuracy, modulo_rounded_accuracy, initialize_save_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a4c5c-b70d-4d2d-9e23-fd5aebf284eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have a GPU in my laptop, which helps a little. Check whether it is detected.\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    print(\"GPU detected\")\n",
    "else:\n",
    "    print(\"No GPU detected; will use only CPU\")\n",
    "    \n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088ab2d-0294-47b0-8528-98cbbbfb15bd",
   "metadata": {},
   "source": [
    "## Config\n",
    "The most important variables to pay attention to:\n",
    "\n",
    "* ENCODER: Which cipher to work on. At the moment, only encoders.ENCODER_CAESAR is doing anything interesting.\n",
    "* INFER_TEXT and INFER_KEY: Whether to work on a model tries to predict decoded text, or just the key. Keys are usually a lot easier.\n",
    "* CHUNK_SIZE: How many characters to process at a time. Smaller is faster and more memory-efficient, larger gives the network more information.\n",
    "* EPOCHS: How many epochs to fit/train the model each time. Bump this up when you want to make a \"final\" model.\n",
    "* ENCRYPTED_FILE_LIMIT: Maximum number of encrypted files to load up. Limit it to work faster.\n",
    "* MAX_TRAIN_COUNT: Maximum number of chunks to include in training set. Limit it to work faster and reduce memory usage.\n",
    "* MAX_TEST_COUNT: Maximum number of chunks to include in test set. Less impactful to memory than training count, but still relevant.\n",
    "* LOAD_BEST_MODEL: Whether to load a model, as opposed to building a new one.\n",
    "* BEST_PATH: Path to save tuned models, or to load models from.\n",
    "* LOAD_SCALER: Whether to load scaler values from disk. If you work with a new encoder/chunk size combination, you'll need to turn this off to save new values, which can be reused later.\n",
    "* TUNE_NETWORK: Whether to run the hyper-tuner, which involves a lot of fiddling with other variables.\n",
    "* TRAIN_MODEL: Whether to train the network. Note you can load a network, then train it more.\n",
    "\n",
    "### Troubleshooting\n",
    "There are three recurring challenges:\n",
    "* **Running Out of Memory**: If you get error messages about OS or GPU memory failures, the first thing to do is restart the kernel. If the problem continues, try reducing these values: chunk size, processing units, max train count, batch size, or (less often) max train count.\n",
    "* **Kernel Crashes**: This is usually caused by memory problems. See above.\n",
    "* **Data Shapes**: If you get errors from numpy or Tensorflow about data shapes, array indexing, or numbers of dimensions, it's probably about the relationship between input (chunks), layers in the network, output, and getting actual useful information from that output. This is just hard. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bdcd65-ceca-4b1a-921a-4544e38b37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = encoders.ENCODER_CAESAR\n",
    "INFER_TEXT = False\n",
    "INFER_KEY = not INFER_TEXT\n",
    "\n",
    "CHUNK_SIZE = 256\n",
    "PROCESSING_UNITS = CHUNK_SIZE//4\n",
    "EPOCHS = 3\n",
    "\n",
    "ENCRYPTED_FILE_LIMIT = -1 # -1 to disable limit\n",
    "\n",
    "BASE_TRAIN_PCT = 0.75   # If train or test count would exceed the max, they will be reduced. Note 0.75 is the default.\n",
    "MAX_TRAIN_COUNT = -1 if INFER_KEY else 100000   # -1 to disable; some setups start running out of memory around 100K\n",
    "MAX_TEST_COUNT =  MAX_TRAIN_COUNT               # -1 to disable\n",
    "\n",
    "LOAD_BEST_MODEL = False # If True, model will be loaded from the path below. If False, a new model will be created from scratch.\n",
    "SAVE_BEST_MODEL = True # During training, whether to keep saving the best-so-far model to disk, at the path below.\n",
    "BEST_PATH = os.path.join(TEMP_MODEL_DIR, \"best.keras\")\n",
    "\n",
    "LOAD_SCALER = True # If true, load from disk. If False, calculate and save to disk.\n",
    "SCALER_PATH = helpers.get_recommended_scaler_path(ENCODER, CHUNK_SIZE)\n",
    "\n",
    "# Whether to run the tuner or the hard-coded network build code\n",
    "TUNE_NETWORK = False\n",
    "TUNE_QUICKLY = False # Set True to sanity check the model builder\n",
    "BUILD_NETWORK = not (TUNE_NETWORK or LOAD_BEST_MODEL)\n",
    "TRAIN_MODEL = BUILD_NETWORK\n",
    "\n",
    "if INFER_TEXT:\n",
    "    MAIN_ACCURACY_METRIC = \"mae\"\n",
    "    LOSS_METRIC = \"mean_squared_error\"\n",
    "    OUTPUT_SIZE = CHUNK_SIZE\n",
    "    OPTIMIZER = PREFERRED_OPTIMIZER\n",
    "else:\n",
    "    MAIN_ACCURACY_METRIC = \"mae\"\n",
    "    LOSS_METRIC = \"mae\"\n",
    "    OPTIMIZER = PREFERRED_OPTIMIZER\n",
    "\n",
    "    if ENCODER == encoders.ENCODER_CAESAR:\n",
    "        OUTPUT_SIZE = 1\n",
    "    elif ENCODER == encoders.ENCODER_SUBST:\n",
    "        OUTPUT_SIZE = len(encoders.CHARSET)\n",
    "    else:\n",
    "        raise Exception(f\"Unsupported encoder {ENCODER}\")\n",
    "\n",
    "# Setting a random seed here for the test/train split means the split will be consistent until\n",
    "# this cell gets rerun. Set it to a specific value to make it always the same.\n",
    "SPLIT_SEED = random.randint(1, 4294967295)\n",
    "\n",
    "TUNER_DIRECTORY = \"tuner_projects\"\n",
    "TUNER_PROJECT_NAME = \"KT\"\n",
    "\n",
    "# Default is batch size is 32.\n",
    "# Going higher speeds things up a LOT, but causes memory problems.\n",
    "# This formula has been working OK, but still requires manual fiddling at times.\n",
    "BATCH_SIZE = int(max(32, round(256 * (512/CHUNK_SIZE))))\n",
    "model_checkpoint_callback = None\n",
    "\n",
    "# Whether to run some (potentially slow) debug checks:\n",
    "EXTRA_CHECKS = False\n",
    "\n",
    "CHUNK_SIZE, PROCESSING_UNITS, BATCH_SIZE, OUTPUT_SIZE, SPLIT_SEED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ec896-6840-4696-bebd-c0419f8a1f69",
   "metadata": {},
   "source": [
    "# Data Retrieval and Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ab2e5-5e11-4812-91be-bb9a63acb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_connect.DB(CONNECTION_INFO)\n",
    "\n",
    "with db.get_session() as session:\n",
    "    # Get database IDs for encoders and key types\n",
    "    (encoder_ids, key_type_id) = db.get_id_maps(session)\n",
    "\n",
    "    # Map source ID to plaintext file (1) details, and source ID to corresponding ciphertext files (1+) details.\n",
    "    # This search will not return any files associated with a \"test_only\" source.\n",
    "    (sid_to_p, sid_to_c) = db.get_source_maps(session, ENCRYPTED_FILE_LIMIT, encoder_ids[ENCODER], test_only=False)\n",
    "\n",
    "    # Get the features (X, the cipher texts as offsets) and targets (y, either the plain texts as offsets OR the key).\n",
    "    (X, y_keys, y_texts) = db.get_features_and_targets(\n",
    "            session, sid_to_p, sid_to_c, ENCODER, CHUNK_SIZE, \n",
    "            want_keys=INFER_KEY or EXTRA_CHECKS, \n",
    "            want_texts=INFER_TEXT or EXTRA_CHECKS)\n",
    "\n",
    "X = np.array(X)\n",
    "if INFER_KEY:\n",
    "    y = np.array(y_keys)\n",
    "if INFER_TEXT:\n",
    "    y = np.array(y_texts)\n",
    "        \n",
    "len(sid_to_p), len(sid_to_c), X.shape, y.shape, sys.getsizeof(X), sys.getsizeof(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72d2c0-2cf4-4d4e-89af-46021e40bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging and extra checks, build up a collection of all known texts\n",
    "\n",
    "all_plaintexts = \"\"\n",
    "all_ciphertexts = \"\"\n",
    "if EXTRA_CHECKS:\n",
    "    # Get ALL the texts in one big string, for debugging\n",
    "    for sid in sid_to_p:\n",
    "        all_plaintexts += helpers.read_text_file(sid_to_p[sid].path)\n",
    "        for c in sid_to_c[sid]:\n",
    "            all_ciphertexts += helpers.read_text_file(c.path)\n",
    "    \n",
    "    # Make sure specified text occurs somewhere in the texts.\n",
    "    # These raise exceptions if not found.\n",
    "    def check_in_plaintext(to_check: str):\n",
    "        if to_check not in all_plaintexts:\n",
    "            raise Exception(f\"Plaintext not found: {to_check}\")\n",
    "    \n",
    "    def check_in_ciphertext(to_check: str):\n",
    "        if to_check not in all_ciphertexts:\n",
    "            raise Exception(f\"Ciphertext not found: {to_check}\")\n",
    "    \n",
    "\n",
    "    checks = round( len(X) * 0.01)\n",
    "    print(f\"Checking {checks} strings\")\n",
    "    for _ in range(checks):\n",
    "        i = random.randint(0, len(X)-1)\n",
    "        check_in_plaintext(encoders.offsets_to_string(y_texts[i].astype(int)))\n",
    "        check_in_ciphertext(encoders.offsets_to_string(X[i].astype(int)))\n",
    "\n",
    "len(all_plaintexts), len(all_ciphertexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55451fa-ee72-4835-b18a-d03d44899412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "# Note we have excluded \"test_only\" files above, they will be used for later validation.\n",
    "\n",
    "train_count = int(round(len(y) * BASE_TRAIN_PCT))\n",
    "if train_count > MAX_TRAIN_COUNT and MAX_TRAIN_COUNT > -1:\n",
    "    print(f\"Train count would be {train_count}\")\n",
    "    train_count = int(MAX_TRAIN_COUNT)\n",
    "print(f\"Train count is {train_count}\")\n",
    "\n",
    "test_count = len(y) - train_count\n",
    "if test_count > MAX_TEST_COUNT and MAX_TEST_COUNT > -1:\n",
    "    print(f\"Test count would be {test_count}\")\n",
    "    test_count = int(MAX_TEST_COUNT)\n",
    "print(f\"Test count is {test_count}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_count, test_size=test_count, random_state=SPLIT_SEED)\n",
    "\n",
    "if EXTRA_CHECKS:\n",
    "    checks = max(10, round( min(len(X_train), len(X_test)) * 0.01))\n",
    "    print(f\"Checking {checks} strings\")\n",
    "    for _ in range(checks):\n",
    "        i = random.randint(0, len(X_train)-1)\n",
    "        check_in_ciphertext(encoders.offsets_to_string(X_train[i].astype(int)))\n",
    "\n",
    "        i = random.randint(0, len(X_test)-1)\n",
    "        check_in_ciphertext(encoders.offsets_to_string(X_test[i].astype(int)))\n",
    "\n",
    "# The pre-split data sets are no longer needed, and take up a lot of memory, so get rid of them\n",
    "if not EXTRA_CHECKS:\n",
    "    del X\n",
    "    del y\n",
    "    del y_keys\n",
    "    del y_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5fd198-2be6-4f66-91ff-0bbb1ccb819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "\n",
    "if LOAD_SCALER:\n",
    "    print(f\"Loading scaler from {SCALER_PATH}\")\n",
    "    X_scaler = helpers.load_scaler_from_file(SCALER_PATH)\n",
    "else:\n",
    "    # Fit the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    print(\"Fitting scaler\")\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    print(f\"Saving scaler to {SCALER_PATH}\")\n",
    "    helpers.save_scaler_to_file(X_scaler, SCALER_PATH)\n",
    "    \n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)   \n",
    "    \n",
    "to_show = min(16, CHUNK_SIZE)\n",
    "X_train_scaled.shape, X_test_scaled.shape, X_train_scaled[0][0:to_show], X_test_scaled[0][0:to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa6ffe-b96c-49ff-abe9-858cd87dabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data as required for the model\n",
    "\n",
    "print(f\"Original shapes: {X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}\")\n",
    "\n",
    "X_train = tf_helpers.reshape_input_for_RNN(X_train, CHUNK_SIZE)\n",
    "X_train_scaled = tf_helpers.reshape_input_for_RNN(X_train_scaled, CHUNK_SIZE)\n",
    "X_test = tf_helpers.reshape_input_for_RNN(X_test, CHUNK_SIZE)\n",
    "X_test_scaled = tf_helpers.reshape_input_for_RNN(X_test_scaled, CHUNK_SIZE)\n",
    "y_train = tf_helpers.reshape_output_for_RNN(y_train, OUTPUT_SIZE)\n",
    "y_test = tf_helpers.reshape_output_for_RNN(y_test, OUTPUT_SIZE)\n",
    "\n",
    "print(f\"Final    shapes: {X_train.shape}, {X_train_scaled.shape}, {X_test.shape}, {X_test_scaled.shape}, {y_train.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340dfc6-d8e6-461c-87af-f2627f638908",
   "metadata": {},
   "source": [
    "# Hyperband Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab864b-b88b-4dac-b504-c58c4fbdc37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_tuner\n",
    "\n",
    "MAX_EPOCHS_PER_MODEL = 20 # Meant to get a decent idea of parameter, not create a final model. Behaves oddly below 3.\n",
    "HYPERBAND_ITERATIONS = 1  # \"Number of times to iterate over the full Hyperband algorithm\"\n",
    "EXECUTIONS_PER_TRIAL = 1  # Training from scratch\n",
    "SEARCH_FIT_EPOCHS = 20    # Epochs for each attempt to do a fit, I think. Not sure how this relates to MAX_EPOCHS_PER_MODEL.\n",
    "OVERWRITE = True          # I'm hoping to be able to interrupt a run and resume it later\n",
    "\n",
    "input_shape = (None, 1, CHUNK_SIZE)\n",
    "mr_t = model_tuner.ModelTuner(input_shape, OUTPUT_SIZE, CHUNK_SIZE, BATCH_SIZE)\n",
    "\n",
    "# All-encompassing optimization parameter choices. Do not try to use all of them at once...\n",
    "mr_t.CHOICES_PROCESSING_UNITS = [1, CHUNK_SIZE // 16, CHUNK_SIZE // 4, CHUNK_SIZE, CHUNK_SIZE * 2]\n",
    "mr_t.CHOICES_ACTIVATIONS = [\"elu\", \"gelu\", \"hard_sigmoid\", \"hard_silu\", \"hard_swish\", \"leaky_relu\", \"linear\", \"log_softmax\", \"mish\",\n",
    "        \"relu\", \"relu6\", \"selu\", \"sigmoid\", \"silu\", \"softmax\", \"softplus\", \"softsign\", \"swish\", \"tanh\"]\n",
    "mr_t.CHOICES_FANCY_TOPO = [\"GRU\", \"RNN\", \"LSTM\", \"GRU-RNN\", \"GRU-LSTM\", \"GRU-RNN-LSTM\"] # Prefer LSTM, GRU-LSTM might be slightly more accurate, but it's so slooooow\n",
    "mr_t.CHOICES_USE_OUTPUT_LIMITER = [True, False] # Prefers False, but barely\n",
    "mr_t.CHOICES_OPTIMIZER = [\"adamax\", \"sgd\", \"RMSProp\", \"adam\", \"Ftrl\", \"Lion\", \"Lamb\"] # Prefers RMSProp\n",
    "\n",
    "# Narrow down the choices as needed.\n",
    "mr_t.CHOICES_PROCESSING_UNITS = [PROCESSING_UNITS]\n",
    "mr_t.CHOICES_FANCY_TOPO = [\"LSTM\"]\n",
    "mr_t.CHOICES_OPTIMIZER = [\"RMSProp\"]\n",
    "mr_t.CHOICES_USE_OUTPUT_LIMITER = [False]\n",
    "mr_t.PICK_FANCY_TOPO_ACTIVATIONS = False\n",
    "\n",
    "if TUNE_QUICKLY:\n",
    "    MAX_EPOCHS_PER_MODEL = 3\n",
    "    HYPERBAND_ITERATIONS = 1\n",
    "    EXECUTIONS_PER_TRIAL = 1\n",
    "    SEARCH_FIT_EPOCHS = 4\n",
    "\n",
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    return mr_t.CreateModel(hp)\n",
    "\n",
    "# Run the kerastuner search for best hyperparameters\n",
    "if TUNE_NETWORK:\n",
    "    if USE_CUSTOM_METRICS:\n",
    "        objective = kt.Objective(\"val_modulo_distance_accuracy\", direction=\"max\")\n",
    "    else:\n",
    "        objective = kt.Objective(f\"val_{MAIN_ACCURACY_METRIC}\", direction=\"max\")\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        create_model,\n",
    "        objective=objective,\n",
    "        max_epochs=MAX_EPOCHS_PER_MODEL,\n",
    "        hyperband_iterations=HYPERBAND_ITERATIONS,\n",
    "        executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
    "        overwrite=OVERWRITE,\n",
    "        directory=TUNER_DIRECTORY,\n",
    "        project_name=TUNER_PROJECT_NAME)\n",
    "    tuner.search(X_train_scaled, y_train, epochs=SEARCH_FIT_EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test_scaled, y_test))\n",
    "    \n",
    "    best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "    print(f\"Best Hyper Values: {best_hyper.values}\")\n",
    "    \n",
    "    nn = tuner.get_best_models(1)[0]\n",
    "    eval_results = nn.evaluate(X_test_scaled, y_test, verbose=2, batch_size=BATCH_SIZE )\n",
    "    print(f\"Best Model Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")\n",
    "\n",
    "    nn.save(\"./saved_models/tuned.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71ca9b-9cc3-4c85-9dab-e4b7d969ca52",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdee2d-2e95-4fb1-96e9-c428546102cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BUILD_NETWORK:\n",
    "    print(\"Building new model\")\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    input_shape = (None, 1, CHUNK_SIZE)    \n",
    "    nn.add(tf.keras.Input(shape=input_shape[1:], name=\"Input_Layer\"))\n",
    "\n",
    "    activation_A = \"tanh\"\n",
    "    recurrent_activation_A = \"sigmoid\"\n",
    "    nn.add(tf.keras.layers.LSTM(\n",
    "        PROCESSING_UNITS, return_sequences=True, activation=activation_A, recurrent_activation=recurrent_activation_A,\n",
    "        name=f\"A_LSTM_{activation_A}_{recurrent_activation_A}\"))\n",
    "    \n",
    "    nn.add(tf.keras.layers.Dense(units = OUTPUT_SIZE, activation=modulo_output, name='Modulo_Layer'))\n",
    "\n",
    "    # Check the structure of the model\n",
    "    print(f\"Input shape: {nn.input_shape}, Output shape: {nn.output_shape}\")\n",
    "    print(nn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c6ff4-2ca0-4ac0-af80-7d48b157675a",
   "metadata": {},
   "source": [
    "# Model Fitting / Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08319c4f-7080-477b-93b8-eca4791c449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"load train loop\" is a manual loop. With this on, this cell can be executed repeatedly to\n",
    "# load the best scoring model, train, save the best scoring model... The idea is to keep improving,\n",
    "# backtracking if scores stagnate or start to worsen.\n",
    "#\n",
    "# This is still pretty fiddly, requiring more manual prep if you're working with a brand new model.\n",
    "LOAD_TRAIN_LOOP = False\n",
    "\n",
    "# Set up a callback to save the model as it improves during training.\n",
    "# Once it has been set up, doing this again effectively \"resets\" the best score,\n",
    "# so be conscious of how you use it. Don't want to reset when iteratively training.\n",
    "if (model_checkpoint_callback is None) or (not LOAD_TRAIN_LOOP):\n",
    "    model_checkpoint_callback = initialize_save_best(BEST_PATH)\n",
    "\n",
    "# Load model from disk\n",
    "if LOAD_BEST_MODEL or LOAD_TRAIN_LOOP:\n",
    "    if os.path.exists(BEST_PATH):\n",
    "        print(f\"Loading model from {BEST_PATH}\")\n",
    "        nn = models.load_model(BEST_PATH)\n",
    "    else:\n",
    "        print(f\"Cannot load model, file not found: {BEST_PATH}\")\n",
    "        \n",
    "# Train the model\n",
    "if TRAIN_MODEL or LOAD_TRAIN_LOOP:\n",
    "    # Decide what metrics to use\n",
    "    if USE_CUSTOM_METRICS:\n",
    "        loss = modulo_distance_loss\n",
    "        metrics = [modulo_distance_accuracy, modulo_rounded_accuracy]\n",
    "    else:\n",
    "        loss = LOSS_METRIC\n",
    "        metrics = [MAIN_ACCURACY_METRIC]\n",
    "\n",
    "    print(nn.summary())\n",
    "    print(f\"Training model\")\n",
    "    \n",
    "    if SAVE_BEST_MODEL:\n",
    "        callbacks = [model_checkpoint_callback]\n",
    "    else:\n",
    "        callbacks = None\n",
    "    \n",
    "    # Compile the Sequential model together and customize metrics\n",
    "    nn.compile(loss=loss, optimizer=OPTIMIZER, metrics=metrics)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    fit_model = nn.fit(X_train_scaled, y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(nn.summary())\n",
    "print(f\"Input shape: {nn.input_shape}, Output shape: {nn.output_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253797a-b692-45c4-b2fe-89e9bb3c0f9a",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Cells below give a few different ways to judge the usefulness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbdff5-d47a-4447-8af8-136396783596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some data for testing below...\n",
    "\n",
    "# Predicting the whole test set can take a lot of memory, so this can be used to limit it:\n",
    "TEST_SET_SIZE = X_test_scaled.shape[0]\n",
    "MAX_TEST_SUBSET = -1\n",
    "TEST_SUBSET_SIZE = min(TEST_SET_SIZE, MAX_TEST_SUBSET) if MAX_TEST_SUBSET > 0 else TEST_SET_SIZE\n",
    "X_test_scaled_subset = X_test_scaled[0:TEST_SUBSET_SIZE, :, :]\n",
    "y_test_subset = y_test[0:TEST_SUBSET_SIZE, :, :]\n",
    "\n",
    "# Sometimes for troubleshooting I want to use the training set, which should produce more accurate predictions:\n",
    "TRAIN_SET_SIZE = X_train_scaled.shape[0]\n",
    "MAX_TRAIN_SUBSET = MAX_TEST_SUBSET\n",
    "TRAIN_SUBSET_SIZE = min(TRAIN_SET_SIZE, MAX_TRAIN_SUBSET) if MAX_TRAIN_SUBSET > 0 else TRAIN_SET_SIZE\n",
    "X_train_scaled_subset = X_train_scaled[0:TRAIN_SUBSET_SIZE, :, :]\n",
    "y_train_subset = y_train[0:TRAIN_SUBSET_SIZE, :, :]\n",
    "\n",
    "use_training_data = False\n",
    "if use_training_data:\n",
    "    print(\"Using training data as input; results are not valid for accuracy but may be informative about function\")\n",
    "    input = X_train_scaled_subset\n",
    "    expected = y_train_subset\n",
    "else:\n",
    "    print(\"Using test data as input\")\n",
    "    input = X_test_scaled_subset\n",
    "    expected = y_test_subset\n",
    "\n",
    "input.shape, expected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58ac5c7-c06f-412f-b5ea-5a78b25d4a68",
   "metadata": {},
   "source": [
    "### Tensorflow Evaluate()\n",
    "Calling model.evaluate() is the easiest and most standard way to measure the model's effectiveness, but I'm not sure the numbers are reliable. Between the use of custom metric functions and my uncertainty about data shape, these results could be misleading.\n",
    "\n",
    "Other cells below look closer at results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347990dc-230b-460f-852d-c2e0e81cef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating test set with model.evaluate() ...\")\n",
    "eval_results = nn.evaluate(X_test_scaled_subset, y_test_subset, batch_size=BATCH_SIZE)\n",
    "print(f\"Test Set        : Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")\n",
    "\n",
    "print(\"Evaluating training set with model.evaluate() --  should tend to be somewhat better...\")\n",
    "eval_results = nn.evaluate(X_train_scaled_subset, y_train_subset, batch_size=BATCH_SIZE)\n",
    "print(f\"Training Set    : Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5974ce11-65de-4f70-859d-558c4b6b16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was used to determine where to find the single best result from\n",
    "# the prediction. It will be moved to the analsis notebook...\n",
    "\n",
    "col_offset = []\n",
    "col_loss = []\n",
    "col_acc_dist = []\n",
    "col_acc_round = []\n",
    "\n",
    "# Looping through individual inputs is horribly slow, but I specifically wanted this\n",
    "# so I could relate behaviors to what I could actually see.\n",
    "HOW_MANY = 10\n",
    "for _ in range(HOW_MANY):\n",
    "    which_input = random.randint(0, input.shape[0]-1)\n",
    "    this_input = input[which_input:which_input+1, :, :]\n",
    "    this_expected = expected[which_input:which_input+1, :, :]\n",
    "\n",
    "    raw_predicted = nn.predict(this_input, batch_size=BATCH_SIZE, verbose=0)\n",
    "    this_predicted = raw_predicted.astype(np.float64)\n",
    "\n",
    "    offsets = range(0, CHUNK_SIZE)\n",
    "    for offset in offsets:\n",
    "        # I don't know why these are different:\n",
    "        if INFER_TEXT:\n",
    "            offset_predicted = this_predicted[:, :, offset]\n",
    "        if INFER_KEY:\n",
    "            offset_predicted = this_predicted[:, offset, :]\n",
    "            \n",
    "        loss = modulo_distance_loss(this_expected, offset_predicted)\n",
    "        accuracy_distance = modulo_distance_accuracy(this_expected, offset_predicted)\n",
    "        accuracy_rounded = modulo_rounded_accuracy(this_expected, offset_predicted)\n",
    "\n",
    "        col_offset.append(offset)\n",
    "        col_loss.append(loss.numpy())\n",
    "        col_acc_dist.append(accuracy_distance.numpy())\n",
    "        col_acc_round.append(accuracy_rounded.numpy())\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Offset\": col_offset,\n",
    "    \"Loss\": col_loss,\n",
    "    \"Accuracy (Distance)\": col_acc_dist,\n",
    "    \"Accuracy (Rounded)\": col_acc_round \n",
    "}).set_index(\"Offset\")\n",
    "\n",
    "metrics_df = metrics_df.groupby(['Offset']).mean()\n",
    "print(metrics_df.describe())\n",
    "metrics_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488ae3d-b10f-40d7-826a-61fedba4cb2b",
   "metadata": {},
   "source": [
    "### Model Usefulness Spot-Check\n",
    "This cell measures accuracy in a more intuitive, but less mathematically rigorous, way. It's also much, much slower, and currently only works with the Caesar cipher.\n",
    "\n",
    "This is mean to supplement the metrics that come out of Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd4fd4-831e-43a5-9351-c0c2cfa1be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many files to check. This is where we disable running with substitution ciphers too.\n",
    "FILES_TO_CHECK = 10 if ENCODER == encoders.ENCODER_CAESAR else 0\n",
    "if INFER_TEXT:    \n",
    "    CHUNKS_TO_CHECK = 10\n",
    "else:\n",
    "    CHUNKS_TO_CHECK = 20\n",
    "    \n",
    "good=0\n",
    "bad=0\n",
    "display_length = 64\n",
    "PRINT_ALL = FILES_TO_CHECK <= 10\n",
    "if INFER_TEXT and PRINT_ALL and FILES_TO_CHECK > 0:\n",
    "    print(\"Note that newline characters will be replaced for display here, for easier reading.\")\n",
    "\n",
    "with db.get_session() as session:\n",
    "    for _ in range(FILES_TO_CHECK):\n",
    "        sid = random.choice(list(sid_to_c.keys()))\n",
    "        cipher_file_db = random.choice(sid_to_c[sid])\n",
    "        ciphertext_path = cipher_file_db.path\n",
    "        ciphertext = helpers.read_text_file(ciphertext_path)\n",
    "        length = min(CHUNK_SIZE * CHUNKS_TO_CHECK, len(ciphertext))\n",
    "        ciphertext = ciphertext[0:length]\n",
    "        \n",
    "        if INFER_KEY:\n",
    "            cracker = Caesar_Cracker(X_scaler, nn, None)            \n",
    "            correct_key = int(db.get_key_by_id(session, cipher_file_db.key_id).value)            \n",
    "            inferred_key = cracker.infer_key_with_model(ciphertext)\n",
    "\n",
    "            if PRINT_ALL:\n",
    "                print(f\"Correct key: {correct_key:03}, Inferred Key: {inferred_key:03}\")\n",
    "    \n",
    "            if correct_key == inferred_key:\n",
    "                good += 1\n",
    "            else:\n",
    "                bad += 1\n",
    "        if INFER_TEXT:\n",
    "            if ENCODER == encoders.ENCODER_CAESAR:\n",
    "                cracker = Caesar_Cracker(X_scaler, None, nn)        \n",
    "                inferred_text = cracker.infer_text_with_model(ciphertext)\n",
    "            if ENCODER == encoders.ENCODER_SUBST:\n",
    "                inferred_text = \"!!!\"\n",
    "\n",
    "            source_file_db =  db.get_files_by_source_and_encoder(session, sid, encoder_ids[encoders.ENCODER_SIMPLIFIER])[0]\n",
    "            plaintext_path = source_file_db.path\n",
    "            plaintext = helpers.read_text_file(plaintext_path)\n",
    "            plaintext = plaintext[0:length]\n",
    "            \n",
    "            if PRINT_ALL:\n",
    "                print(f\"Ciphertext:\\n\", ciphertext[0:display_length].replace(\"\\n\", \" \"))\n",
    "                print(f\"Decoded:\\n\", inferred_text[0:display_length].replace(\"\\n\", \" \"))\n",
    "                print(f\"Plaintext:\\n\", plaintext[0:display_length].replace(\"\\n\", \" \"))\n",
    "                print()\n",
    "\n",
    "            (this_good, this_bad, _, _) = helpers.good_bad_string_match(inferred_text, plaintext)\n",
    "            good += this_good\n",
    "            bad += this_bad\n",
    "    \n",
    "if good + bad > 0:\n",
    "    good_percent = float(good)/float(good+bad)\n",
    "    luck_percent = float(1)/float(len(encoders.CHARSET))\n",
    "    \n",
    "    print(f\"Good results: {good} / {bad} ({good_percent:.2%})\")\n",
    "    print(f\"Chance of randomly getting something right: {luck_percent:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
