{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bca2471e-572c-4233-b18c-e8e03e8cf40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import pathlib\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from credentials import SAMPLE_DB, FULL_DB\n",
    "from librarian import SAMPLE_DATA_DIR\n",
    "\n",
    "import encoders\n",
    "import db_connect\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088ab2d-0294-47b0-8528-98cbbbfb15bd",
   "metadata": {},
   "source": [
    "## Config\n",
    "This notebook has a lot of options to adjust, most of which are controlled here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9bdcd65-ceca-4b1a-921a-4544e38b37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = SAMPLE_DATA_DIR\n",
    "ENCODER = encoders.ENCODER_CAESAR\n",
    "CHUNK_SIZE = 512\n",
    "PROCESSING_UNITS = CHUNK_SIZE // 4\n",
    "LAYER_UNITS = max(1, CHUNK_SIZE // 10)\n",
    "\n",
    "INFER_TEXT = False\n",
    "INFER_KEY = not INFER_TEXT\n",
    "\n",
    "USE_CUSTOM_LOSS = True\n",
    "USE_CUSTOM_OUTPUT_ACTIVATION = True\n",
    "\n",
    "OUTPUT_MIN = 0\n",
    "OUTPUT_MAX = len(encoders.CHARSET)-1\n",
    "CUSTOM_LOSS_MODULO = OUTPUT_MAX+1\n",
    "\n",
    "if INFER_TEXT:\n",
    "    MAIN_ACCURACY_METRIC = \"mae\"\n",
    "    LOSS_METRIC = \"mean_squared_error\"\n",
    "    OUTPUT_SIZE = CHUNK_SIZE\n",
    "    OPTIMIZER = \"sgd\"\n",
    "else:\n",
    "    MAIN_ACCURACY_METRIC = \"mae\"\n",
    "    LOSS_METRIC = \"mae\"\n",
    "    OPTIMIZER = \"adamax\"    \n",
    "\n",
    "    if ENCODER == encoders.ENCODER_CAESAR:\n",
    "        OUTPUT_SIZE = 1\n",
    "    elif ENCODER == encoders.ENCODER_SUBST:\n",
    "        OUTPUT_SIZE = len(encoders.CHARSET)\n",
    "    else:\n",
    "        raise Exception(f\"Unsupported encoder {ENCODER}\")\n",
    "\n",
    "ENCRYPTED_FILE_LIMIT = 100 # -1 to disable limit\n",
    "\n",
    "BASE_TRAIN_PCT = 0.75   # Start here. If train or test count would exceed the max, reduce it. Note 0.75 is the default.\n",
    "MAX_TRAIN_COUNT = 100000 # -1 to disable (not recommended, things crash after about 100K)\n",
    "MAX_TEST_COUNT =  100000 # -1 to disable (not recommended, things crash after about 100K)\n",
    "SPLIT_SEED = 42\n",
    "\n",
    "LOAD_BEST_MODEL = False # If False, a new model will be created from scratch\n",
    "SAVE_BEST_MODEL = True\n",
    "BEST_PATH = './saved_models/best.keras'\n",
    "\n",
    "# Whether to run the tuner or the hard-coded network build code\n",
    "TUNE_NETWORK = False\n",
    "BUILD_NETWORK = not TUNE_NETWORK\n",
    "TRAIN_MODEL = BUILD_NETWORK\n",
    "\n",
    "TUNER_DIRECTORY = \"tuner_projects\"\n",
    "TUNER_PROJECT_NAME = \"KT\"\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256 # Default is 32 -- going higher speeds things up a LOT, but may cause memory problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ec896-6840-4696-bebd-c0419f8a1f69",
   "metadata": {},
   "source": [
    "# Data Retrieval and Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "789ab2e5-5e11-4812-91be-bb9a63acb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder IDs: {'None': 1, 'Simplifier': 2, 'Caesar Cipher': 3, 'Substitution Cipher': 4, 'Enigma Machine': 5}\n",
      "Key Type IDs: {'Character Offset': 1, 'Character Map': 2, 'Rotor Settings': 3}\n"
     ]
    }
   ],
   "source": [
    "# Get database IDs for encoders and key types\n",
    "\n",
    "encoder_ids= {}\n",
    "key_type_ids = {}\n",
    "\n",
    "db = db_connect.DB(SAMPLE_DB)\n",
    "with db.get_session() as session:\n",
    "    for encoder in encoders.ALL_ENCODER_NAMES:\n",
    "        id = db.get_encoder_id(session, encoder)\n",
    "        encoder_ids[encoder] = id\n",
    "\n",
    "    print(f\"Encoder IDs: {encoder_ids}\")\n",
    "\n",
    "    for key_type in encoders.KEY_NAMES:\n",
    "        id = db.get_key_type_id(session, key_type)\n",
    "        key_type_ids[key_type] = id\n",
    "\n",
    "    print(f\"Key Type IDs: {key_type_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0fc8e5ca-4b37-4947-9e79-f061cc993a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 720 encrypted files\n",
      "Using 100 encrypted files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18, 18)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map source ID to plaintext file (1) details, and source ID to corresponding ciphertext files (1+) details\n",
    "sid_to_p = {}\n",
    "sid_to_c = {}\n",
    "\n",
    "cipher_id = encoder_ids[ENCODER]\n",
    "with db.get_session() as session:\n",
    "    # Get all files encrypted with the cipher we care about\n",
    "    encrypted_files = db.get_files_by_source_and_encoder(session, -1, cipher_id)\n",
    "\n",
    "    if len(encrypted_files) > ENCRYPTED_FILE_LIMIT and ENCRYPTED_FILE_LIMIT > 0:\n",
    "        print(f\"Found {len(encrypted_files)} encrypted files\")\n",
    "        encrypted_files = random.sample(encrypted_files, ENCRYPTED_FILE_LIMIT)\n",
    "    print(f\"Using {len(encrypted_files)} encrypted files\")\n",
    "\n",
    "    for c in encrypted_files:\n",
    "        sid = c.source_id\n",
    "    \n",
    "        if sid not in sid_to_p:\n",
    "            plaintext_ids = db.get_files_by_source_and_encoder(session, sid, encoder_ids[encoders.ENCODER_SIMPLIFIER])\n",
    "            if len(plaintext_ids) != 1:\n",
    "                raise Exception(f\"Found {len(plaintext_ids)} plaintexts for source ID {sid}; should be exactly 1\")\n",
    "            sid_to_p[sid] = plaintext_ids[0]\n",
    "\n",
    "        if sid not in sid_to_c:\n",
    "            sid_to_c[sid] = []\n",
    "        sid_to_c[sid].append(c)\n",
    "\n",
    "len(sid_to_p), len(sid_to_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3f6de1c-79f8-4637-8dec-ade266665517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81215, 512), (81215,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build up the features (X, the cipher texts as offsets) and targets (y, either the plain texts as offsets OR the key).\n",
    "# Note targets are not necessarily unique.\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "with db.get_session() as session:\n",
    "    for sid in sid_to_p:\n",
    "        if INFER_TEXT:\n",
    "            plaintext = encoders.string_to_offsets(helpers.read_text_file(sid_to_p[sid].path))\n",
    "            target_chunks = helpers.chunkify(plaintext, CHUNK_SIZE)    \n",
    "    \n",
    "        for c in sid_to_c[sid]:\n",
    "            ciphertext = encoders.string_to_offsets(helpers.read_text_file(c.path))\n",
    "            feature_chunks = helpers.chunkify(ciphertext, CHUNK_SIZE)\n",
    "\n",
    "            if INFER_KEY:                \n",
    "                if ENCODER == encoders.ENCODER_CAESAR:\n",
    "                    key_value = float(db.get_key_by_id(session, c.key_id).value)\n",
    "                elif ENCODER == encoders.ENCODER_SUBST:\n",
    "                    raise Exception(f\"Not yet implemented key for {ENCODER}\")\n",
    "                else:\n",
    "                    raise Exception(f\"Unsupported encoder {ENCODER}\")\n",
    "        \n",
    "            for i in range (len(feature_chunks)):\n",
    "                X.append(np.array(feature_chunks[i]).astype(float))\n",
    "\n",
    "                if INFER_TEXT:\n",
    "                    y.append(np.array(target_chunks[i]).astype(float))\n",
    "\n",
    "                if INFER_KEY:\n",
    "                    y.append(key_value)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e55451fa-ee72-4835-b18a-d03d44899412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count is 60911\n",
      "Test count is 20304\n",
      "Initial counts:  81215 81215 60911 20304 60911 20304\n"
     ]
    }
   ],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "train_count = int(round(len(y) * BASE_TRAIN_PCT))\n",
    "if train_count > MAX_TRAIN_COUNT and MAX_TRAIN_COUNT > -1:\n",
    "    print(f\"Train count would be {train_count}\")\n",
    "    train_count = int(MAX_TRAIN_COUNT)\n",
    "print(f\"Train count is {train_count}\")\n",
    "\n",
    "test_count = len(y) - train_count\n",
    "if test_count > MAX_TEST_COUNT and MAX_TEST_COUNT > -1:\n",
    "    print(f\"Test count would be {test_count}\")\n",
    "    test_count = int(MAX_TEST_COUNT)\n",
    "print(f\"Test count is {test_count}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_count, test_size=test_count, random_state=SPLIT_SEED)\n",
    "print( \"Initial counts: \", len(X), len(y), len(X_train), len(X_test), len(y_train), len(y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d5fd198-2be6-4f66-91ff-0bbb1ccb819f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60911, 512), (20304, 512))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3300c5-1772-41d7-b5e7-f790fceb6074",
   "metadata": {},
   "source": [
    "# Tensorflow Callbacks\n",
    "Custom layer activation function, loss and accuracy functions, and model save checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b3de2a3-9271-49ab-ace6-c175d2e46720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom output activation, forcing output to be within range -- but not rounding it off\n",
    "# Possibly not needed, sigmoid + rescaler might work just as well\n",
    "def modulo_output(x):\n",
    "    return tf.math.mod(x, OUTPUT_MAX)\n",
    "\n",
    "# Custom loss function, adapted from code generated by Copilot\n",
    "def modulo_distance_loss(y_true, y_pred):\n",
    "    \"\"\" Custom loss function to compute the modulo distance. \n",
    "    Args: \n",
    "        y_true: True values (ground truth). \n",
    "        y_pred: Predicted values. \n",
    "        modulo: The modulo value to apply -- hard coded.\n",
    "    Returns: \n",
    "        The computed loss. \n",
    "    \"\"\" \n",
    "    # Compute the raw difference\n",
    "    diff = tf.abs(y_true - y_pred)\n",
    "    # Apply modulo operation to handle wrap-around cases\n",
    "    mod_diff = tf.math.mod(diff, CUSTOM_LOSS_MODULO)\n",
    "    # Ensure the distance is within the range [0, CUSTOM_LOSS_MODULO/2]\n",
    "    loss = tf.minimum(mod_diff, CUSTOM_LOSS_MODULO - mod_diff) \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Custom accuracy function, counterpart to the loss function above.\n",
    "# Returns accuracy as 1 - (average percent distance from correct value)\n",
    "def modulo_distance_accuracy(y_true, y_pred):\n",
    "    diff = tf.abs(y_true - y_pred)\n",
    "    mod_diff = tf.math.mod(diff, CUSTOM_LOSS_MODULO)\n",
    "    loss = tf.minimum(mod_diff, CUSTOM_LOSS_MODULO - mod_diff)\n",
    "\n",
    "    good_part = tf.math.subtract(CUSTOM_LOSS_MODULO / 2, loss)\n",
    "    accuracy = tf.math.divide(good_part, CUSTOM_LOSS_MODULO / 2)\n",
    "\n",
    "    return tf.reduce_mean(accuracy)\n",
    "\n",
    "# Custom accuracy, percent of correct values after rounding and doing modulo division\n",
    "def modulo_rounded_accuracy(y_true, y_pred):\n",
    "    # y_true SHOULD all be round, in-bounds numbers but just in case...\n",
    "    true_rounded = tf.math.round(y_true)\n",
    "    true_mod = tf.math.mod(true_rounded, CUSTOM_LOSS_MODULO)\n",
    "\n",
    "    # y_pred came straight from the model, so it needs to be rounded and mod'ed\n",
    "    pred_rounded = tf.math.round(y_pred)\n",
    "    pred_mod = tf.math.mod(pred_rounded, CUSTOM_LOSS_MODULO)\n",
    "\n",
    "    # Count matches, as a percentage by averaging all the 0's and 1's\n",
    "    matches_bool = tf.math.equal(true_mod, pred_mod)\n",
    "    matches_float = tf.cast(matches_bool, tf.float64)\n",
    "    return tf.reduce_mean(matches_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6fd9e25-9167-4ee5-85cd-b16e9c7a8c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true: tf.Tensor(\n",
      "[[  1.   2.   3. 310.]\n",
      " [  1.   2.   3. 310.]], shape=(2, 4), dtype=float64)\n",
      "pred: tf.Tensor(\n",
      "[[ 0.4  1.5  3.5 62.4]\n",
      " [ 0.4  1.5  3.5 62.4]], shape=(2, 4), dtype=float64)\n",
      "rond: tf.Tensor(\n",
      "[[ 0.  2.  4. 62.]\n",
      " [ 0.  2.  4. 62.]], shape=(2, 4), dtype=float64)\n",
      "diff tf.Tensor(\n",
      "[[  0.6   0.5   0.5 247.6]\n",
      " [  0.6   0.5   0.5 247.6]], shape=(2, 4), dtype=float64)\n",
      "loss: tf.Tensor(0.5000000000000014, shape=(), dtype=float64)\n",
      "accD: tf.Tensor(0.9838709677419354, shape=(), dtype=float64)\n",
      "accR: tf.Tensor(0.5, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#!!! Scratch for testing my loss and accuracy functions\n",
    "t_true = [[1.0, 2.0, 3.0, CUSTOM_LOSS_MODULO*5]]*2\n",
    "t_pred = [[0.4, 1.5, 3.5, CUSTOM_LOSS_MODULO + 0.4]]*2\n",
    "\n",
    "t_true_ts = tf.constant(np.array(t_true).astype(float))\n",
    "t_pred_ts = tf.constant(np.array(t_pred).astype(float))\n",
    "loss = modulo_distance_loss(t_true_ts, t_pred_ts)\n",
    "accD = modulo_distance_accuracy(t_true_ts, t_pred_ts)\n",
    "accR = modulo_rounded_accuracy(t_true_ts, t_pred_ts)\n",
    "print(\"true:\", t_true_ts)\n",
    "print(\"pred:\", t_pred_ts)\n",
    "print(\"rond:\", tf.math.round(t_pred_ts))\n",
    "print(\"diff\", abs(t_true_ts - t_pred_ts))\n",
    "print(\"loss:\", loss)\n",
    "print(\"accD:\", accD)\n",
    "print(\"accR:\", accR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340dfc6-d8e6-461c-87af-f2627f638908",
   "metadata": {},
   "source": [
    "# Hyperband Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13b11ccc-1c3b-4947-afb0-4872e4d5b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_FAST = False\n",
    "\n",
    "MAX_EPOCHS_PER_MODEL = 15 # Meant to get a decent idea of parameter, not create a final model. Behaves oddly below 3.\n",
    "HYPERBAND_ITERATIONS = 1  # \"Number of times to iterate over the full Hyperband algorithm\"\n",
    "EXECUTIONS_PER_TRIAL = 1  # Training from scratch\n",
    "SEARCH_FIT_EPOCHS = 10    # Epochs for each attempt to do a fit, I think. Not sure how this relates to MAX_EPOCHS_PER_MODEL.\n",
    "OVERWRITE = True         # I'm hoping to be able to interrupt a run and resume it later\n",
    "\n",
    "CHOICES_PROCESSING_UNITS = [1, CHUNK_SIZE // 16, CHUNK_SIZE // 4, CHUNK_SIZE, CHUNK_SIZE * 2] # Prefers 128 (CHUNK_SIZE // 4)\n",
    "CHOICES_FANCY_TOPO = [\"NONE\", \"GRU\", \"RNN\", \"LSTM\", \"GRU-RNN\", \"GRU-LSTM\", \"GRU-RNN-LSTM\"]     # LSTM seems to win\n",
    "CHOICES_USE_SIGMOID = [True, False] # Prefers True\n",
    "CHOICES_SIGMOID_SIZE_TO_OUTPUT = [True, False] # Prefers False\n",
    "CHOICES_USE_SCALER = [True, False] # Only relevant when using Sigmoid -- prefers True\n",
    "CHOICES_USE_OUTPUT_LIMITER = [True, False] # Prefers True\n",
    "CHOICES_OPTIMIZER = [\"adamax\", \"sgd\", \"RMSProp\"] # Prefers adamax\n",
    "\n",
    "#!!!\n",
    "CHOICES_PROCESSING_UNITS = [1, CHUNK_SIZE // 16, CHUNK_SIZE // 4, CHUNK_SIZE, CHUNK_SIZE * 2]\n",
    "CHOICES_FANCY_TOPO = [\"LSTM\"]\n",
    "CHOICES_USE_SIGMOID = [True]\n",
    "CHOICES_SIGMOID_SIZE_TO_OUTPUT = [False]\n",
    "CHOICES_USE_SCALER = [True]\n",
    "CHOICES_USE_OUTPUT_LIMITER = [True]\n",
    "CHOICES_OPTIMIZER = [\"adamax\", \"sgd\", \"RMSProp\"]\n",
    "\n",
    "if GO_FAST:\n",
    "    MAX_EPOCHS_PER_MODEL = 3\n",
    "    SEARCH_FIT_EPOCHS = 4\n",
    "    CHOICES_FANCY_TOPO = [\"NONE\", \"RNN\"]\n",
    "    CHOICES_PROCESSING_UNITS = [1, 8]\n",
    "    CHOICES_OPTIMIZER = [\"adamax\"]\n",
    "\n",
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    processing_units = hp.Choice(\"Processing_Units\", CHOICES_PROCESSING_UNITS)\n",
    "    fancy_topo = hp.Choice(\"Fancy_Topology\", CHOICES_FANCY_TOPO)\n",
    "    use_sigmoid = hp.Choice(\"Sigmoid\", CHOICES_USE_SIGMOID)    \n",
    "    use_output_limiter = hp.Choice(\"Output_Limiter\", CHOICES_USE_OUTPUT_LIMITER)\n",
    "    optimizer = hp.Choice(\"Optimizer\", CHOICES_OPTIMIZER)\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=CHUNK_SIZE, output_dim=processing_units, name=\"Embedding_Input\"))\n",
    "\n",
    "    if fancy_topo == \"NONE\":\n",
    "        pass\n",
    "    elif fancy_topo == \"GRU\":\n",
    "        model.add(tf.keras.layers.GRU(PROCESSING_UNITS))\n",
    "    elif fancy_topo == \"RNN\":\n",
    "        model.add(tf.keras.layers.SimpleRNN(PROCESSING_UNITS))\n",
    "    elif fancy_topo == \"LSTM\":\n",
    "        model.add(tf.keras.layers.LSTM(PROCESSING_UNITS))\n",
    "    elif fancy_topo == \"GRU-RNN\":\n",
    "        model.add(tf.keras.layers.GRU(PROCESSING_UNITS, return_sequences=True))\n",
    "        model.add(tf.keras.layers.SimpleRNN(PROCESSING_UNITS))\n",
    "    elif fancy_topo == \"GRU-LSTM\":\n",
    "        model.add(tf.keras.layers.GRU(PROCESSING_UNITS, return_sequences=True))\n",
    "        model.add(tf.keras.layers.LSTM(PROCESSING_UNITS))\n",
    "    elif fancy_topo == \"GRU-RNN-LSTM\":\n",
    "        model.add(tf.keras.layers.GRU(PROCESSING_UNITS, return_sequences=True))\n",
    "        model.add(tf.keras.layers.SimpleRNN(PROCESSING_UNITS, return_sequences=True))\n",
    "        model.add(tf.keras.layers.LSTM(PROCESSING_UNITS))\n",
    "    else:\n",
    "        raise Exception(f\"Bad choice {fancy_topo}\")\n",
    "\n",
    "\n",
    "    if use_sigmoid:\n",
    "        # The sigmoid layer can be sized like a processing unit or for output,\n",
    "        # but that only matters if those values are different\n",
    "        if OUTPUT_SIZE != processing_units:\n",
    "            # There are two possibilities, so allow checking both\n",
    "            sigmoid_size_to_output = hp.Choice(\"Sigmoid_Size_To_Output\", CHOICES_SIGMOID_SIZE_TO_OUTPUT)\n",
    "            sigmoid_units = OUTPUT_SIZE if sigmoid_size_to_output else processing_units\n",
    "        else:\n",
    "            # The two values are the same, so just use that value\n",
    "            sigmoid_units = OUTPUT_SIZE\n",
    "    \n",
    "        model.add(tf.keras.layers.Dense(units=processing_units, activation=\"sigmoid\", name=\"Sigmoid\"))\n",
    "        use_scaler = hp.Choice(\"Scaler\", CHOICES_USE_SCALER)\n",
    "        if use_scaler:\n",
    "            model.add(tf.keras.layers.Rescaling(scale=OUTPUT_MAX, offset=0, name=\"Rescaler\")) # Input is 0-1\n",
    "    \n",
    "    if use_output_limiter:\n",
    "        model.add(tf.keras.layers.Dense(OUTPUT_SIZE, activation=modulo_output, name=\"Output_Limiter\"))\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Dense(OUTPUT_SIZE, name=\"Linear_Output\"))\n",
    "\n",
    "    # Compile the model\n",
    "    if USE_CUSTOM_LOSS:\n",
    "        loss = modulo_distance_loss\n",
    "        metrics = [modulo_distance_accuracy, modulo_rounded_accuracy]\n",
    "    else:\n",
    "        loss = LOSS_METRIC\n",
    "        metrics = [MAIN_ACCURACY_METRIC]\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Run the kerastuner search for best hyperparameters\n",
    "if TUNE_NETWORK:\n",
    "\n",
    "    if USE_CUSTOM_LOSS:\n",
    "        objective = kt.Objective(\"val_loss\", direction=\"min\")\n",
    "    else:\n",
    "        objective = kt.Objective(f\"val_{MAIN_ACCURACY_METRIC}\", direction=\"max\")\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        create_model,\n",
    "        objective=objective,\n",
    "        max_epochs=MAX_EPOCHS_PER_MODEL,\n",
    "        hyperband_iterations=HYPERBAND_ITERATIONS,\n",
    "        executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
    "        overwrite=OVERWRITE,\n",
    "        directory=TUNER_DIRECTORY,\n",
    "        project_name=TUNER_PROJECT_NAME)\n",
    "    tuner.search(X_train_scaled, y_train, epochs=SEARCH_FIT_EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test_scaled,y_test))\n",
    "    \n",
    "    best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "    print(f\"Best Hyper Values: {best_hyper.values}\")\n",
    "    \n",
    "    nn = tuner.get_best_models(1)[0]\n",
    "    eval_results = nn.evaluate(X_test_scaled, y_test, verbose=2, batch_size=BATCH_SIZE )\n",
    "    print(f\"Best Model Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")\n",
    "\n",
    "    nn.save(\"./saved_models/tuned.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71ca9b-9cc3-4c85-9dab-e4b7d969ca52",
   "metadata": {},
   "source": [
    "# Model Reload /Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0fdee2d-2e95-4fb1-96e9-c428546102cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building new model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Embedding_Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Sigmoid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Rescaler (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Limiter (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Embedding_Input (\u001b[38;5;33mEmbedding\u001b[0m)     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ LSTM (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Sigmoid (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Rescaler (\u001b[38;5;33mRescaling\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Limiter (\u001b[38;5;33mDense\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if LOAD_BEST_MODEL:\n",
    "    print(f\"Loading model from {BEST_PATH}\")\n",
    "    nn = tf.keras.models.load_model(BEST_PATH)\n",
    "elif BUILD_NETWORK:\n",
    "    print(\"Building new model\")\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    nn.add(tf.keras.layers.Embedding(input_dim=CHUNK_SIZE, output_dim=PROCESSING_UNITS, name=\"Embedding_Input\"))\n",
    "    nn.add(tf.keras.layers.LSTM(PROCESSING_UNITS, name=\"LSTM\"))\n",
    "    nn.add(tf.keras.layers.Dense(units=PROCESSING_UNITS, activation=\"sigmoid\", name=\"Sigmoid\"))\n",
    "    nn.add(tf.keras.layers.Rescaling(scale=OUTPUT_MAX, offset=0, name=\"Rescaler\")) # Input is 0-1\n",
    "    nn.add(tf.keras.layers.Dense(OUTPUT_SIZE, activation=modulo_output, name=\"Output_Limiter\"))\n",
    "\n",
    "else:\n",
    "    print(\"Nothing to do here. Hopefully you got a model somewhere above...\")\n",
    "        \n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c6ff4-2ca0-4ac0-af80-7d48b157675a",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "08319c4f-7080-477b-93b8-eca4791c449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Epoch 1/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 6.5491 - modulo_distance_accuracy: 0.5426 - modulo_rounded_accuracy: 0.0190\n",
      "Epoch 1: loss improved from inf to 4.02030, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 6.5385 - modulo_distance_accuracy: 0.5425 - modulo_rounded_accuracy: 0.0190\n",
      "Epoch 2/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.9590 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0194\n",
      "Epoch 2: loss improved from 4.02030 to 1.89493, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 1.9587 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0194\n",
      "Epoch 3/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.8013 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0197\n",
      "Epoch 3: loss improved from 1.89493 to 1.78494, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 1.8012 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0197\n",
      "Epoch 4/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.5852 - modulo_distance_accuracy: 0.5223 - modulo_rounded_accuracy: 0.0206\n",
      "Epoch 4: loss improved from 1.78494 to 1.55699, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 1.5850 - modulo_distance_accuracy: 0.5223 - modulo_rounded_accuracy: 0.0206\n",
      "Epoch 5/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.8307 - modulo_distance_accuracy: 0.5220 - modulo_rounded_accuracy: 0.0212\n",
      "Epoch 5: loss did not improve from 1.55699\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 1.8308 - modulo_distance_accuracy: 0.5220 - modulo_rounded_accuracy: 0.0212\n",
      "Epoch 6/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.7853 - modulo_distance_accuracy: 0.5209 - modulo_rounded_accuracy: 0.0199\n",
      "Epoch 6: loss did not improve from 1.55699\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.7848 - modulo_distance_accuracy: 0.5209 - modulo_rounded_accuracy: 0.0199\n",
      "Epoch 7/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.3825 - modulo_distance_accuracy: 0.5223 - modulo_rounded_accuracy: 0.0219\n",
      "Epoch 7: loss improved from 1.55699 to 1.41272, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 1.3827 - modulo_distance_accuracy: 0.5223 - modulo_rounded_accuracy: 0.0219\n",
      "Epoch 8/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.4871 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0225\n",
      "Epoch 8: loss did not improve from 1.41272\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.4870 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0225\n",
      "Epoch 9/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.4359 - modulo_distance_accuracy: 0.5214 - modulo_rounded_accuracy: 0.0223\n",
      "Epoch 9: loss did not improve from 1.41272\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.4358 - modulo_distance_accuracy: 0.5214 - modulo_rounded_accuracy: 0.0223\n",
      "Epoch 10/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.8446 - modulo_distance_accuracy: 0.5221 - modulo_rounded_accuracy: 0.0210\n",
      "Epoch 10: loss did not improve from 1.41272\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.8453 - modulo_distance_accuracy: 0.5221 - modulo_rounded_accuracy: 0.0210\n",
      "Epoch 11/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.5461 - modulo_distance_accuracy: 0.5212 - modulo_rounded_accuracy: 0.0215\n",
      "Epoch 11: loss did not improve from 1.41272\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.5460 - modulo_distance_accuracy: 0.5212 - modulo_rounded_accuracy: 0.0215\n",
      "Epoch 12/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.4721 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0219\n",
      "Epoch 12: loss did not improve from 1.41272\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.4719 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0219\n",
      "Epoch 13/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.3706 - modulo_distance_accuracy: 0.5221 - modulo_rounded_accuracy: 0.0226\n",
      "Epoch 13: loss improved from 1.41272 to 1.37102, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.3706 - modulo_distance_accuracy: 0.5221 - modulo_rounded_accuracy: 0.0226\n",
      "Epoch 14/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.4729 - modulo_distance_accuracy: 0.5207 - modulo_rounded_accuracy: 0.0221\n",
      "Epoch 14: loss did not improve from 1.37102\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.4737 - modulo_distance_accuracy: 0.5208 - modulo_rounded_accuracy: 0.0221\n",
      "Epoch 15/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.5641 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0210\n",
      "Epoch 15: loss did not improve from 1.37102\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 1.5637 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0210\n",
      "Epoch 16/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.4787 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0215\n",
      "Epoch 16: loss did not improve from 1.37102\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 1.4789 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0215\n",
      "Epoch 17/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.4975 - modulo_distance_accuracy: 0.5230 - modulo_rounded_accuracy: 0.0219\n",
      "Epoch 17: loss did not improve from 1.37102\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.4975 - modulo_distance_accuracy: 0.5230 - modulo_rounded_accuracy: 0.0219\n",
      "Epoch 18/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.4025 - modulo_distance_accuracy: 0.5224 - modulo_rounded_accuracy: 0.0220\n",
      "Epoch 18: loss did not improve from 1.37102\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.4029 - modulo_distance_accuracy: 0.5224 - modulo_rounded_accuracy: 0.0220\n",
      "Epoch 19/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.3669 - modulo_distance_accuracy: 0.5219 - modulo_rounded_accuracy: 0.0225\n",
      "Epoch 19: loss did not improve from 1.37102\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 1.3670 - modulo_distance_accuracy: 0.5219 - modulo_rounded_accuracy: 0.0225\n",
      "Epoch 20/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.4279 - modulo_distance_accuracy: 0.5214 - modulo_rounded_accuracy: 0.0220\n",
      "Epoch 20: loss did not improve from 1.37102\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - loss: 1.4277 - modulo_distance_accuracy: 0.5214 - modulo_rounded_accuracy: 0.0220\n",
      "Epoch 21/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.3990 - modulo_distance_accuracy: 0.5223 - modulo_rounded_accuracy: 0.0223\n",
      "Epoch 21: loss did not improve from 1.37102\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 1.3990 - modulo_distance_accuracy: 0.5223 - modulo_rounded_accuracy: 0.0223\n",
      "Epoch 22/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.3934 - modulo_distance_accuracy: 0.5215 - modulo_rounded_accuracy: 0.0224\n",
      "Epoch 22: loss did not improve from 1.37102\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 1.3935 - modulo_distance_accuracy: 0.5215 - modulo_rounded_accuracy: 0.0224\n",
      "Epoch 23/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.3602 - modulo_distance_accuracy: 0.5216 - modulo_rounded_accuracy: 0.0224\n",
      "Epoch 23: loss did not improve from 1.37102\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 1.3605 - modulo_distance_accuracy: 0.5216 - modulo_rounded_accuracy: 0.0224\n",
      "Epoch 24/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.3201 - modulo_distance_accuracy: 0.5219 - modulo_rounded_accuracy: 0.0230\n",
      "Epoch 24: loss improved from 1.37102 to 1.32323, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 1.3201 - modulo_distance_accuracy: 0.5219 - modulo_rounded_accuracy: 0.0230\n",
      "Epoch 25/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.3364 - modulo_distance_accuracy: 0.5211 - modulo_rounded_accuracy: 0.0227\n",
      "Epoch 25: loss did not improve from 1.32323\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 1.3364 - modulo_distance_accuracy: 0.5211 - modulo_rounded_accuracy: 0.0227\n",
      "Epoch 26/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.2940 - modulo_distance_accuracy: 0.5223 - modulo_rounded_accuracy: 0.0236\n",
      "Epoch 26: loss did not improve from 1.32323\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 1.2941 - modulo_distance_accuracy: 0.5223 - modulo_rounded_accuracy: 0.0236\n",
      "Epoch 27/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.3026 - modulo_distance_accuracy: 0.5223 - modulo_rounded_accuracy: 0.0234\n",
      "Epoch 27: loss improved from 1.32323 to 1.32312, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 1.3028 - modulo_distance_accuracy: 0.5222 - modulo_rounded_accuracy: 0.0234\n",
      "Epoch 28/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.3627 - modulo_distance_accuracy: 0.5207 - modulo_rounded_accuracy: 0.0227\n",
      "Epoch 28: loss did not improve from 1.32312\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 1.3631 - modulo_distance_accuracy: 0.5207 - modulo_rounded_accuracy: 0.0227\n",
      "Epoch 29/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.3266 - modulo_distance_accuracy: 0.5213 - modulo_rounded_accuracy: 0.0232\n",
      "Epoch 29: loss did not improve from 1.32312\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - loss: 1.3270 - modulo_distance_accuracy: 0.5213 - modulo_rounded_accuracy: 0.0232\n",
      "Epoch 30/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.3956 - modulo_distance_accuracy: 0.5203 - modulo_rounded_accuracy: 0.0221\n",
      "Epoch 30: loss did not improve from 1.32312\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - loss: 1.3954 - modulo_distance_accuracy: 0.5203 - modulo_rounded_accuracy: 0.0221\n",
      "Epoch 31/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.2901 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0235\n",
      "Epoch 31: loss improved from 1.32312 to 1.28305, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - loss: 1.2901 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0235\n",
      "Epoch 32/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.2736 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0234\n",
      "Epoch 32: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - loss: 1.2737 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0234\n",
      "Epoch 33/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.2743 - modulo_distance_accuracy: 0.5216 - modulo_rounded_accuracy: 0.0237\n",
      "Epoch 33: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - loss: 1.2745 - modulo_distance_accuracy: 0.5216 - modulo_rounded_accuracy: 0.0237\n",
      "Epoch 34/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.2883 - modulo_distance_accuracy: 0.5214 - modulo_rounded_accuracy: 0.0236\n",
      "Epoch 34: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 1.2883 - modulo_distance_accuracy: 0.5214 - modulo_rounded_accuracy: 0.0236\n",
      "Epoch 35/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.3102 - modulo_distance_accuracy: 0.5213 - modulo_rounded_accuracy: 0.0236\n",
      "Epoch 35: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 1.3101 - modulo_distance_accuracy: 0.5213 - modulo_rounded_accuracy: 0.0236\n",
      "Epoch 36/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.2804 - modulo_distance_accuracy: 0.5219 - modulo_rounded_accuracy: 0.0236\n",
      "Epoch 36: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 1.2805 - modulo_distance_accuracy: 0.5219 - modulo_rounded_accuracy: 0.0236\n",
      "Epoch 37/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.3218 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0228\n",
      "Epoch 37: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 1.3216 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0228\n",
      "Epoch 38/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.3033 - modulo_distance_accuracy: 0.5213 - modulo_rounded_accuracy: 0.0236\n",
      "Epoch 38: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 54ms/step - loss: 1.3035 - modulo_distance_accuracy: 0.5213 - modulo_rounded_accuracy: 0.0236\n",
      "Epoch 39/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.2838 - modulo_distance_accuracy: 0.5216 - modulo_rounded_accuracy: 0.0235\n",
      "Epoch 39: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 55ms/step - loss: 1.2839 - modulo_distance_accuracy: 0.5216 - modulo_rounded_accuracy: 0.0235\n",
      "Epoch 40/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.2971 - modulo_distance_accuracy: 0.5211 - modulo_rounded_accuracy: 0.0237\n",
      "Epoch 40: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 55ms/step - loss: 1.2971 - modulo_distance_accuracy: 0.5211 - modulo_rounded_accuracy: 0.0237\n",
      "Epoch 41/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.6110 - modulo_distance_accuracy: 0.5208 - modulo_rounded_accuracy: 0.0221\n",
      "Epoch 41: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - loss: 1.6110 - modulo_distance_accuracy: 0.5208 - modulo_rounded_accuracy: 0.0221\n",
      "Epoch 42/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.2872 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0234\n",
      "Epoch 42: loss did not improve from 1.28305\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - loss: 1.2872 - modulo_distance_accuracy: 0.5217 - modulo_rounded_accuracy: 0.0234\n",
      "Epoch 43/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.2123 - modulo_distance_accuracy: 0.5224 - modulo_rounded_accuracy: 0.0241\n",
      "Epoch 43: loss improved from 1.28305 to 1.19278, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 56ms/step - loss: 1.2122 - modulo_distance_accuracy: 0.5224 - modulo_rounded_accuracy: 0.0241\n",
      "Epoch 44/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.1804 - modulo_distance_accuracy: 0.5213 - modulo_rounded_accuracy: 0.0246\n",
      "Epoch 44: loss improved from 1.19278 to 1.18347, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - loss: 1.1804 - modulo_distance_accuracy: 0.5213 - modulo_rounded_accuracy: 0.0246\n",
      "Epoch 45/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.1887 - modulo_distance_accuracy: 0.5207 - modulo_rounded_accuracy: 0.0243\n",
      "Epoch 45: loss did not improve from 1.18347\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 1.1889 - modulo_distance_accuracy: 0.5207 - modulo_rounded_accuracy: 0.0243\n",
      "Epoch 46/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.1762 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0248\n",
      "Epoch 46: loss did not improve from 1.18347\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.1765 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0248\n",
      "Epoch 47/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.1730 - modulo_distance_accuracy: 0.5214 - modulo_rounded_accuracy: 0.0250\n",
      "Epoch 47: loss improved from 1.18347 to 1.18246, saving model to ./saved_models/best.keras\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 1.1731 - modulo_distance_accuracy: 0.5214 - modulo_rounded_accuracy: 0.0250\n",
      "Epoch 48/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 1.2430 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0244\n",
      "Epoch 48: loss did not improve from 1.18246\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 1.2433 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0244\n",
      "Epoch 49/50\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.2165 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0249\n",
      "Epoch 49: loss did not improve from 1.18246\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 1.2165 - modulo_distance_accuracy: 0.5218 - modulo_rounded_accuracy: 0.0249\n",
      "Epoch 50/50\n",
      "\u001b[1m237/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.2850 - modulo_distance_accuracy: 0.5220 - modulo_rounded_accuracy: 0.0248\n",
      "Epoch 50: loss did not improve from 1.18246\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 1.2855 - modulo_distance_accuracy: 0.5220 - modulo_rounded_accuracy: 0.0248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Embedding_Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ LSTM (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Sigmoid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Rescaler (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Limiter (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Embedding_Input (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m65,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ LSTM (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Sigmoid (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Rescaler (\u001b[38;5;33mRescaling\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Limiter (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">641,285</span> (2.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m641,285\u001b[0m (2.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">213,761</span> (835.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m213,761\u001b[0m (835.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">427,524</span> (1.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m427,524\u001b[0m (1.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 9s, sys: 1min 33s, total: 7min 42s\n",
      "Wall time: 9min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    # Training checkpoint to save after each epoch, if it is a new best model:\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=BEST_PATH,\n",
    "        monitor=\"loss\",\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1)\n",
    "\n",
    "    print(f\"Training model\")\n",
    "\n",
    "    if USE_CUSTOM_LOSS:\n",
    "        loss = modulo_distance_loss\n",
    "        metrics = [modulo_distance_accuracy, modulo_rounded_accuracy]\n",
    "    else:\n",
    "        loss = LOSS_METRIC\n",
    "        metrics = [MAIN_ACCURACY_METRIC]\n",
    "    \n",
    "    if SAVE_BEST_MODEL:\n",
    "        callbacks = [model_checkpoint_callback]\n",
    "    else:\n",
    "        callbacks = None\n",
    "    \n",
    "    # Compile the Sequential model together and customize metrics\n",
    "    nn.compile(loss=loss, optimizer=OPTIMIZER, metrics=metrics)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    fit_model = nn.fit(X_train_scaled, y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=BATCH_SIZE)\n",
    "\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "347990dc-230b-460f-852d-c2e0e81cef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with model.evaluate() ...\n",
      "80/80 - 2s - 19ms/step - loss: 1.2489 - modulo_distance_accuracy: 0.5229 - modulo_rounded_accuracy: 0.0253\n",
      "Loss: 1.2489447593688965, Accuracy: [0.5228797197341919, 0.025341644883155823]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "\n",
    "#!!! My custom metric functions are running out of memory for some reason...\n",
    "if False:    \n",
    "    print(\"Evaluating with model.predict() ...\")\n",
    "    raw_pred = nn.predict(X_test_scaled, batch_size=BATCH_SIZE)\n",
    "    print(\"A...\")\n",
    "    y_pred = tf.constant(np.array(raw_pred).astype(np.float64))\n",
    "    print(\"B...\")\n",
    "    loss = modulo_distance_loss(y_test, y_pred)\n",
    "    loss = modulo_distance_loss(tf.constant(y_test), tf.constant(y_pred))\n",
    "    print(\"C...\")\n",
    "    accuracy_distance = modulo_distance_accuracy(y_test, y_pred)\n",
    "    print(\"D...\")\n",
    "    accuracy_rounded = modulo_rounded_accuracy(y_test, y_pred)\n",
    "    print(\"E...\")\n",
    "    print(f\"Loss: {loss:0.6}, Accuracy (Distance): {accuracy_distance:0.6}, Accuracy (Rounded): {accuracy_rounded:0.6}\")\n",
    "\n",
    "    pred_pd = pd.DataFrame(y_pred.numpy())\n",
    "    print(pred_pd.describe())\n",
    "\n",
    "print(\"Evaluating with model.evaluate() ...\")\n",
    "eval_results = nn.evaluate(X_test_scaled, y_test, verbose=2, batch_size=BATCH_SIZE)\n",
    "print(f\"Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488ae3d-b10f-40d7-826a-61fedba4cb2b",
   "metadata": {},
   "source": [
    "# Model Usefulness Spot-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4abd4fd4-831e-43a5-9351-c0c2cfa1be2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Key:  21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Inferred Key:  42\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "[[45.159256]\n",
      " [42.632664]\n",
      " [42.680344]\n",
      " [42.487907]\n",
      " [42.456577]\n",
      " [41.162918]\n",
      " [41.328995]\n",
      " [42.096886]\n",
      " [41.072803]\n",
      " [40.993828]\n",
      " [41.54249 ]\n",
      " [42.19113 ]\n",
      " [42.31713 ]\n",
      " [41.716343]\n",
      " [42.775177]\n",
      " [40.85258 ]\n",
      " [45.07912 ]\n",
      " [41.935387]\n",
      " [41.788406]\n",
      " [41.155766]]\n"
     ]
    }
   ],
   "source": [
    "def decode_chunks_with_model(chunks: list[list], model, scaler, input_already_scaled = True) -> list[list]:\n",
    "    if input_already_scaled:\n",
    "        return model.predict(chunks)\n",
    "    else:\n",
    "        return model.predict(scaler.transform(chunks))\n",
    "\n",
    "def decode_text_with_model(ciphertext: str, model, scaler) -> str:\n",
    "    offset_chunks = helpers.chunkify(encoders.string_to_offsets(ciphertext), CHUNK_SIZE)\n",
    "    decoded_chunks = decode_chunks_with_model(offset_chunks, model, scaler, input_already_scaled = False)\n",
    "    rounded = np.rint(decoded_chunks.flatten()).astype(int)\n",
    "    return encoders.offsets_to_string(rounded)\n",
    "\n",
    "def infer_key_with_model(ciphertext: str, model, scaler) -> int:\n",
    "    chunks = helpers.string_to_bytes(ciphertext, CHUNK_SIZE)\n",
    "    keys = model.predict(scaler.transform(chunks))\n",
    "    key = int(round(np.median(keys)))\n",
    "    return key\n",
    "\n",
    "if INFER_TEXT:    \n",
    "    CHUNKS_TO_CHECK = 2\n",
    "else:\n",
    "    CHUNKS_TO_CHECK = 20\n",
    "\n",
    "cipher_file_db = sid_to_c[list(sid_to_c.keys())[0]][0]\n",
    "ciphertext_path = cipher_file_db.path\n",
    "ciphertext = helpers.read_text_file(ciphertext_path)\n",
    "ciphertext = ciphertext[0:CHUNK_SIZE * CHUNKS_TO_CHECK]\n",
    "    \n",
    "if INFER_TEXT:    \n",
    "    print(\"Decoded   : \", decode_text_with_model(ciphertext, nn, X_scaler))\n",
    "if INFER_KEY:\n",
    "    with db.get_session() as session:\n",
    "        correct_key = int(db.get_key_by_id(session, cipher_file_db.key_id).value)\n",
    "    print(\"Correct Key: \", correct_key)\n",
    "    \n",
    "    inferred_key = infer_key_with_model(ciphertext, nn, X_scaler)\n",
    "    print(\"Inferred Key: \", inferred_key)\n",
    "\n",
    "chunks = helpers.string_to_bytes(ciphertext, CHUNK_SIZE)\n",
    "print(nn.predict(scaler.transform(chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca1c384-8e11-4541-a33c-59f14cb7ecf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
