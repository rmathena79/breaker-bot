{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257e4334-a266-4af7-8a69-d2268f65d0e7",
   "metadata": {},
   "source": [
    "# Modeler\n",
    "\n",
    "This notebook is meant to be used interactively, to create models for breaking codes. It assumes you have already used the Librarian script to populate your filesystem and database.\n",
    "\n",
    "## How to Use This File\n",
    "\n",
    "... Good question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca2471e-572c-4233-b18c-e8e03e8cf40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 12:03:56.759092: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-02 12:03:56.833681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-02 12:03:56.873745: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-02 12:03:56.883078: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-02 12:03:56.959463: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import pathlib\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from credentials import CONNECTION_INFO\n",
    "from constants import *\n",
    "from crackers import Caesar_Cracker\n",
    "\n",
    "import encoders\n",
    "import db_connect\n",
    "import helpers\n",
    "import tf_helpers\n",
    "\n",
    "# Callbacks for use with TensorFlow\n",
    "from tf_helpers import modulo_output, modulo_distance_loss, modulo_distance_accuracy, modulo_rounded_accuracy, initialize_save_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088ab2d-0294-47b0-8528-98cbbbfb15bd",
   "metadata": {},
   "source": [
    "## Config\n",
    "The most important variables to pay attention to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9bdcd65-ceca-4b1a-921a-4544e38b37b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 64, 512, 256)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENCODER = encoders.ENCODER_CAESAR\n",
    "INFER_TEXT = True\n",
    "INFER_KEY = not INFER_TEXT\n",
    "\n",
    "CHUNK_SIZE = 256\n",
    "PROCESSING_UNITS = CHUNK_SIZE//4\n",
    "EPOCHS = 50\n",
    "\n",
    "ENCRYPTED_FILE_LIMIT = -1 # -1 to disable limit\n",
    "\n",
    "BASE_TRAIN_PCT = 0.75   # If train or test count would exceed the max, they will be reduced. Note 0.75 is the default.\n",
    "MAX_TRAIN_COUNT = -1 if INFER_KEY else 100000   # -1 to disable; some setups start running out of memory around 100K\n",
    "MAX_TEST_COUNT =  MAX_TRAIN_COUNT               # -1 to disable\n",
    "\n",
    "LOAD_BEST_MODEL = True # If False, a new model will be created from scratch\n",
    "SAVE_BEST_MODEL = True\n",
    "BEST_PATH = './saved_models/best.keras'\n",
    "\n",
    "LOAD_SCALER = True # If true, load from disk. If False, calculate and save to disk.\n",
    "SCALER_PATH = helpers.get_recommended_scaler_path(ENCODER, CHUNK_SIZE)\n",
    "\n",
    "# Whether to run the tuner or the hard-coded network build code\n",
    "TUNE_NETWORK = False\n",
    "TUNE_QUICKLY = False # Set True to sanity check the model builder\n",
    "BUILD_NETWORK = not TUNE_NETWORK\n",
    "TRAIN_MODEL = BUILD_NETWORK and not LOAD_BEST_MODEL\n",
    "\n",
    "if INFER_TEXT:\n",
    "    MAIN_ACCURACY_METRIC = \"mae\"\n",
    "    LOSS_METRIC = \"mean_squared_error\"\n",
    "    OUTPUT_SIZE = CHUNK_SIZE\n",
    "    OPTIMIZER = \"RMSProp\"\n",
    "else:\n",
    "    MAIN_ACCURACY_METRIC = \"mae\"\n",
    "    LOSS_METRIC = \"mae\"\n",
    "    OPTIMIZER = \"RMSProp\"    \n",
    "\n",
    "    if ENCODER == encoders.ENCODER_CAESAR:\n",
    "        OUTPUT_SIZE = 1\n",
    "    elif ENCODER == encoders.ENCODER_SUBST:\n",
    "        OUTPUT_SIZE = len(encoders.CHARSET)\n",
    "    else:\n",
    "        raise Exception(f\"Unsupported encoder {ENCODER}\")\n",
    "\n",
    "SPLIT_SEED = 42\n",
    "\n",
    "TUNER_DIRECTORY = \"tuner_projects\"\n",
    "TUNER_PROJECT_NAME = \"KT\"\n",
    "\n",
    "BATCH_SIZE = int(max(32, round(256 * (512/CHUNK_SIZE)))) # Default is 32 -- going higher speeds things up a LOT, but may cause memory problems\n",
    "\n",
    "# Whether to run some (potentially slow) debug checks:\n",
    "EXTRA_CHECKS = False\n",
    "\n",
    "CHUNK_SIZE, PROCESSING_UNITS, BATCH_SIZE, OUTPUT_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ec896-6840-4696-bebd-c0419f8a1f69",
   "metadata": {},
   "source": [
    "# Data Retrieval and Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789ab2e5-5e11-4812-91be-bb9a63acb6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, (535650, 256), (535650, 256), 1097011328, 1097011328)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = db_connect.DB(CONNECTION_INFO)\n",
    "\n",
    "with db.get_session() as session:\n",
    "    # Get database IDs for encoders and key types\n",
    "    (encoder_ids, key_type_id) = db.get_id_maps(session)\n",
    "\n",
    "    # Map source ID to plaintext file (1) details, and source ID to corresponding ciphertext files (1+) details\n",
    "    (sid_to_p, sid_to_c) = db.get_source_maps(session, ENCRYPTED_FILE_LIMIT, encoder_ids[ENCODER], test_only=False)\n",
    "\n",
    "    # Get the features (X, the cipher texts as offsets) and targets (y, either the plain texts as offsets OR the key).\n",
    "    (X, y_keys, y_texts) = db.get_features_and_targets(session, sid_to_p, sid_to_c, ENCODER, CHUNK_SIZE, want_keys=INFER_KEY, want_texts=INFER_TEXT)\n",
    "\n",
    "X = np.array(X)\n",
    "if INFER_KEY:\n",
    "    y = np.array(y_keys)\n",
    "if INFER_TEXT:\n",
    "    y = np.array(y_texts)\n",
    "        \n",
    "len(sid_to_p), len(sid_to_c), X.shape, y.shape, sys.getsizeof(X), sys.getsizeof(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e72d2c0-2cf4-4d4e-89af-46021e40bbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugging...\n",
    "\n",
    "all_plaintexts = \"\"\n",
    "all_ciphertexts = \"\"\n",
    "if EXTRA_CHECKS:\n",
    "    # Get ALL the texts in one big string, for debugging\n",
    "    for sid in sid_to_p:\n",
    "        all_plaintexts += helpers.read_text_file(sid_to_p[sid].path)\n",
    "        for c in sid_to_c[sid]:\n",
    "            all_ciphertexts += helpers.read_text_file(c.path)\n",
    "    \n",
    "    # Make sure specified text occurs somewhere in the texts.\n",
    "    # These raise exceptions if not found.\n",
    "    def check_in_plaintext(to_check: str):\n",
    "        if to_check not in all_plaintexts:\n",
    "            raise Exception(f\"Plaintext not found: {to_check}\")\n",
    "    \n",
    "    def check_in_ciphertext(to_check: str):\n",
    "        if to_check not in all_ciphertexts:\n",
    "            raise Exception(f\"Ciphertext not found: {to_check}\")\n",
    "    \n",
    "\n",
    "    checks = round( len(X) * 0.01)\n",
    "    print(f\"Checking {checks} strings\")\n",
    "    for _ in range(checks):\n",
    "        i = random.randint(0, len(X)-1)\n",
    "        check_in_plaintext(encoders.offsets_to_string(y_texts[i].astype(int)))\n",
    "        check_in_ciphertext(encoders.offsets_to_string(X[i].astype(int)))\n",
    "\n",
    "len(all_plaintexts), len(all_ciphertexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55451fa-ee72-4835-b18a-d03d44899412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count would be 401738\n",
      "Train count is 100000\n",
      "Test count would be 435650\n",
      "Test count is 100000\n"
     ]
    }
   ],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "# Note we have excluded \"test_only\" files above, they will be used for later validation.\n",
    "\n",
    "train_count = int(round(len(y) * BASE_TRAIN_PCT))\n",
    "if train_count > MAX_TRAIN_COUNT and MAX_TRAIN_COUNT > -1:\n",
    "    print(f\"Train count would be {train_count}\")\n",
    "    train_count = int(MAX_TRAIN_COUNT)\n",
    "print(f\"Train count is {train_count}\")\n",
    "\n",
    "test_count = len(y) - train_count\n",
    "if test_count > MAX_TEST_COUNT and MAX_TEST_COUNT > -1:\n",
    "    print(f\"Test count would be {test_count}\")\n",
    "    test_count = int(MAX_TEST_COUNT)\n",
    "print(f\"Test count is {test_count}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_count, test_size=test_count, random_state=SPLIT_SEED)\n",
    "\n",
    "if EXTRA_CHECKS:\n",
    "    checks = max(10, round( min(len(X_train), len(X_test)) * 0.01))\n",
    "    print(f\"Checking {checks} strings\")\n",
    "    for _ in range(checks):\n",
    "        i = random.randint(0, len(X_train)-1)\n",
    "        check_in_ciphertext(encoders.offsets_to_string(X_train[i].astype(int)))\n",
    "\n",
    "        i = random.randint(0, len(X_test)-1)\n",
    "        check_in_ciphertext(encoders.offsets_to_string(X_test[i].astype(int)))\n",
    "\n",
    "# The pre-split data sets are no longer needed, and take up a lot of memory, so get rid of them\n",
    "if not EXTRA_CHECKS:\n",
    "    del X\n",
    "    del y\n",
    "    del y_keys\n",
    "    del y_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5fd198-2be6-4f66-91ff-0bbb1ccb819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scaler from ./saved_models/scaler_Caesar_Cipher_000256.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((100000, 256),\n",
       " (100000, 256),\n",
       " array([-1.8166039 , -1.41643136, -1.12956415, -1.6435932 , -1.70068077,\n",
       "         1.5682185 , -0.60780222, -1.41690122, -0.78486035, -1.47280157,\n",
       "         1.57009276, -0.78376302, -1.46963708, -1.64677028,  1.6262305 ,\n",
       "        -1.70272721]),\n",
       " array([-0.55514241, -0.95714604, -1.18698783, -1.29906363, -1.18433153,\n",
       "        -1.52807995, -0.60780222, -1.12984069, -1.53077882, -1.07113234,\n",
       "        -0.60955782, -0.78376302, -1.23998657, -1.53189791, -0.78137369,\n",
       "        -0.03791958]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a StandardScaler instances\n",
    "\n",
    "if LOAD_SCALER:\n",
    "    print(f\"Loading scaler from {SCALER_PATH}\")\n",
    "    X_scaler = helpers.load_scaler_from_file(SCALER_PATH)\n",
    "else:\n",
    "    # Fit the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    print(\"Fitting scaler\")\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    print(f\"Saving scaler to {SCALER_PATH}\")\n",
    "    helpers.save_scaler_to_file(X_scaler, SCALER_PATH)\n",
    "    \n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)   \n",
    "    \n",
    "to_show = min(16, CHUNK_SIZE)\n",
    "X_train_scaled.shape, X_test_scaled.shape, X_train_scaled[0][0:to_show], X_test_scaled[0][0:to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fffa6ffe-b96c-49ff-abe9-858cd87dabde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: (100000, 256), (100000, 256), (100000, 256), (100000, 256)\n",
      "Final    shapes: (100000, 256, 1), (100000, 256, 1), (100000, 256, 1), (100000, 256, 1), (100000, 256, 1), (100000, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data as required for the model\n",
    "\n",
    "print(f\"Original shapes: {X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}\")\n",
    "\n",
    "X_train = tf_helpers.reshape_input(X_train, CHUNK_SIZE)\n",
    "X_train_scaled = tf_helpers.reshape_input(X_train_scaled, CHUNK_SIZE)\n",
    "X_test = tf_helpers.reshape_input(X_test, CHUNK_SIZE)\n",
    "X_test_scaled = tf_helpers.reshape_input(X_test_scaled, CHUNK_SIZE)\n",
    "y_train = tf_helpers.reshape_output(y_train, OUTPUT_SIZE)\n",
    "y_test = tf_helpers.reshape_output(y_test, OUTPUT_SIZE)\n",
    "\n",
    "print(f\"Final    shapes: {X_train.shape}, {X_train_scaled.shape}, {X_test.shape}, {X_test_scaled.shape}, {y_train.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340dfc6-d8e6-461c-87af-f2627f638908",
   "metadata": {},
   "source": [
    "# Hyperband Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ab864b-b88b-4dac-b504-c58c4fbdc37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_tuner\n",
    "\n",
    "MAX_EPOCHS_PER_MODEL = 20 # Meant to get a decent idea of parameter, not create a final model. Behaves oddly below 3.\n",
    "HYPERBAND_ITERATIONS = 1  # \"Number of times to iterate over the full Hyperband algorithm\"\n",
    "EXECUTIONS_PER_TRIAL = 1  # Training from scratch\n",
    "SEARCH_FIT_EPOCHS = 20    # Epochs for each attempt to do a fit, I think. Not sure how this relates to MAX_EPOCHS_PER_MODEL.\n",
    "OVERWRITE = True          # I'm hoping to be able to interrupt a run and resume it later\n",
    "\n",
    "input_shape = (None, 1, CHUNK_SIZE)\n",
    "mr_t = model_tuner.ModelTuner(input_shape, OUTPUT_SIZE, CHUNK_SIZE, BATCH_SIZE)\n",
    "\n",
    "# All-encompassing optimization parameter choices. Do not try to use all of them at once...\n",
    "mr_t.CHOICES_PROCESSING_UNITS = [1, CHUNK_SIZE // 16, CHUNK_SIZE // 4, CHUNK_SIZE, CHUNK_SIZE * 2]\n",
    "mr_t.CHOICES_ACTIVATIONS = [\"elu\", \"gelu\", \"hard_sigmoid\", \"hard_silu\", \"hard_swish\", \"leaky_relu\", \"linear\", \"log_softmax\", \"mish\",\n",
    "        \"relu\", \"relu6\", \"selu\", \"sigmoid\", \"silu\", \"softmax\", \"softplus\", \"softsign\", \"swish\", \"tanh\"]\n",
    "mr_t.CHOICES_FANCY_TOPO = [\"GRU\", \"RNN\", \"LSTM\", \"GRU-RNN\", \"GRU-LSTM\", \"GRU-RNN-LSTM\"] # Prefer LSTM, GRU-LSTM might be slightly more accurate, but it's so slooooow\n",
    "mr_t.CHOICES_USE_OUTPUT_LIMITER = [True, False] # Prefers False, but barely\n",
    "mr_t.CHOICES_OPTIMIZER = [\"adamax\", \"sgd\", \"RMSProp\", \"adam\", \"Ftrl\", \"Lion\", \"Lamb\"] # Prefers RMSProp\n",
    "\n",
    "# Narrow down the choices as needed.\n",
    "mr_t.CHOICES_PROCESSING_UNITS = [PROCESSING_UNITS]\n",
    "mr_t.CHOICES_FANCY_TOPO = [\"LSTM\"]\n",
    "mr_t.CHOICES_OPTIMIZER = [\"RMSProp\"]\n",
    "mr_t.CHOICES_USE_OUTPUT_LIMITER = [False]\n",
    "mr_t.PICK_FANCY_TOPO_ACTIVATIONS = False\n",
    "\n",
    "if TUNE_QUICKLY:\n",
    "    MAX_EPOCHS_PER_MODEL = 3\n",
    "    HYPERBAND_ITERATIONS = 1\n",
    "    EXECUTIONS_PER_TRIAL = 1\n",
    "    SEARCH_FIT_EPOCHS = 4\n",
    "\n",
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    return mr_t.CreateModel(hp)\n",
    "\n",
    "# Run the kerastuner search for best hyperparameters\n",
    "if TUNE_NETWORK:\n",
    "    if USE_CUSTOM_METRICS:\n",
    "        objective = kt.Objective(\"val_modulo_distance_accuracy\", direction=\"max\")\n",
    "    else:\n",
    "        objective = kt.Objective(f\"val_{MAIN_ACCURACY_METRIC}\", direction=\"max\")\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        create_model,\n",
    "        objective=objective,\n",
    "        max_epochs=MAX_EPOCHS_PER_MODEL,\n",
    "        hyperband_iterations=HYPERBAND_ITERATIONS,\n",
    "        executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
    "        overwrite=OVERWRITE,\n",
    "        directory=TUNER_DIRECTORY,\n",
    "        project_name=TUNER_PROJECT_NAME)\n",
    "    tuner.search(X_train_scaled, y_train, epochs=SEARCH_FIT_EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test_scaled, y_test))\n",
    "    \n",
    "    best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "    print(f\"Best Hyper Values: {best_hyper.values}\")\n",
    "    \n",
    "    nn = tuner.get_best_models(1)[0]\n",
    "    eval_results = nn.evaluate(X_test_scaled, y_test, verbose=2, batch_size=BATCH_SIZE )\n",
    "    print(f\"Best Model Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")\n",
    "\n",
    "    nn.save(\"./saved_models/tuned.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71ca9b-9cc3-4c85-9dab-e4b7d969ca52",
   "metadata": {},
   "source": [
    "# Model Reload /Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0fdee2d-2e95-4fb1-96e9-c428546102cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733169894.705343  123849 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733169894.951384  123849 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733169894.951450  123849 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733169894.956534  123849 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733169894.956589  123849 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733169894.956611  123849 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733169896.122106  123849 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733169896.122250  123849 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-02 12:04:56.122294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1733169896.122390  123849 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-02 12:04:56.122455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5363 MB memory:  -> device: 0, name: NVIDIA RTX 2000 Ada Generation Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (None, 1, 256), Output shape: (None, 1, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ A_LSTM_tanh_sigmoid (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Modulo_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ A_LSTM_tanh_sigmoid (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m82,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Modulo_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m16,640\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> (386.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m98,816\u001b[0m (386.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> (386.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,816\u001b[0m (386.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "if BUILD_NETWORK:\n",
    "    print(\"Building new model\")\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    input_shape = (None, 1, CHUNK_SIZE)\n",
    "    nn.add(tf.keras.Input(shape=input_shape[1:], name=\"Input_Layer\"))\n",
    "\n",
    "    activation_A = \"tanh\"\n",
    "    recurrent_activation_A = \"sigmoid\"\n",
    "    nn.add(tf.keras.layers.LSTM(\n",
    "        PROCESSING_UNITS, return_sequences=True, activation=activation_A, recurrent_activation=recurrent_activation_A,\n",
    "        name=f\"A_LSTM_{activation_A}_{recurrent_activation_A}\"))\n",
    "\n",
    "    nn.add(tf.keras.layers.Dense(units = OUTPUT_SIZE, activation=modulo_output, name='Modulo_Layer'))\n",
    "\n",
    "# Check the structure of the model\n",
    "print(f\"Input shape: {nn.input_shape}, Output shape: {nn.output_shape}\")\n",
    "print(nn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c6ff4-2ca0-4ac0-af80-7d48b157675a",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08319c4f-7080-477b-93b8-eca4791c449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./saved_models/best.keras\n",
      "Input shape: (None, 1, 256), Output shape: (None, 1, 256)\n"
     ]
    }
   ],
   "source": [
    "# Reset the \"best\" score and set up a callback to save the model as it improves during training.\n",
    "# If you're manually training iteratively, comment this out to preserve the best-ness:\n",
    "model_checkpoint_callback = initialize_save_best(BEST_PATH)\n",
    "\n",
    "# It can be helpful to load the best, train some more, and try to improve it:\n",
    "if LOAD_BEST_MODEL:\n",
    "    if os.path.exists(BEST_PATH):\n",
    "        print(f\"Loading model from {BEST_PATH}\")\n",
    "        nn = tf.keras.models.load_model(BEST_PATH,\n",
    "            custom_objects={\n",
    "                'modulo_distance_loss': modulo_distance_loss,\n",
    "                'modulo_distance_accuracy': modulo_distance_accuracy,\n",
    "                'modulo_rounded_accuracy': modulo_rounded_accuracy,\n",
    "                'modulo_output': modulo_output\n",
    "        })\n",
    "\n",
    "# Train the model\n",
    "if TRAIN_MODEL:\n",
    "    # Decide what metrics to use\n",
    "    if USE_CUSTOM_METRICS:\n",
    "        loss = modulo_distance_loss\n",
    "        metrics = [modulo_distance_accuracy, modulo_rounded_accuracy]\n",
    "    else:\n",
    "        loss = LOSS_METRIC\n",
    "        metrics = [MAIN_ACCURACY_METRIC]\n",
    "\n",
    "    print(nn.summary())\n",
    "    print(f\"Training model\")\n",
    "    \n",
    "    if SAVE_BEST_MODEL:\n",
    "        callbacks = [model_checkpoint_callback]\n",
    "    else:\n",
    "        callbacks = None\n",
    "    \n",
    "    # Compile the Sequential model together and customize metrics\n",
    "    nn.compile(loss=loss, optimizer=OPTIMIZER, metrics=metrics)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    fit_model = nn.fit(X_train_scaled, y_train, epochs=EPOCHS, callbacks=callbacks, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Input shape: {nn.input_shape}, Output shape: {nn.output_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253797a-b692-45c4-b2fe-89e9bb3c0f9a",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56fbdff5-d47a-4447-8af8-136396783596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using test data as input\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((100000, 256, 1), (100000, 256, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select some data for testing below...\n",
    "\n",
    "# Predicting the whole test set can take a lot of memory, so this can be used to limit it:\n",
    "TEST_SET_SIZE = X_test_scaled.shape[0]\n",
    "MAX_TEST_SUBSET = -1\n",
    "TEST_SUBSET_SIZE = min(TEST_SET_SIZE, MAX_TEST_SUBSET) if MAX_TEST_SUBSET > 0 else TEST_SET_SIZE\n",
    "X_test_scaled_subset = X_test_scaled[0:TEST_SUBSET_SIZE, :, :]\n",
    "y_test_subset = y_test[0:TEST_SUBSET_SIZE, :, :]\n",
    "\n",
    "# Sometimes for troubleshooting I want to use the training set, which should produce more accurate predictions:\n",
    "TRAIN_SET_SIZE = X_train_scaled.shape[0]\n",
    "MAX_TRAIN_SUBSET = MAX_TEST_SUBSET\n",
    "TRAIN_SUBSET_SIZE = min(TRAIN_SET_SIZE, MAX_TRAIN_SUBSET) if MAX_TRAIN_SUBSET > 0 else TRAIN_SET_SIZE\n",
    "X_train_scaled_subset = X_train_scaled[0:TRAIN_SUBSET_SIZE, :, :]\n",
    "y_train_subset = y_train[0:TRAIN_SUBSET_SIZE, :, :]\n",
    "\n",
    "use_training_data = False\n",
    "if use_training_data:\n",
    "    print(\"Using training data as input; results are not valid for accuracy but may be informative about function\")\n",
    "    input = X_train_scaled_subset\n",
    "    expected = y_train_subset\n",
    "else:\n",
    "    print(\"Using test data as input\")\n",
    "    input = X_test_scaled_subset\n",
    "    expected = y_test_subset\n",
    "\n",
    "input.shape, expected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "347990dc-230b-460f-852d-c2e0e81cef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test set with model.evaluate() ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 12:04:57.289935: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - loss: 1.2299 - modulo_distance_accuracy: 0.9603 - modulo_rounded_accuracy: 0.4377\n",
      "Test Set        : Loss: 1.2267991304397583, Accuracy: [0.9604331851005554, 0.4386834502220154]\n",
      "Evaluating training set with model.evaluate() ...\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 1.2234 - modulo_distance_accuracy: 0.9605 - modulo_rounded_accuracy: 0.4397\n",
      "Training Set    : Loss: 1.2252131700515747, Accuracy: [0.9604777097702026, 0.4394630491733551]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating test set with model.evaluate() ...\")\n",
    "eval_results = nn.evaluate(X_test_scaled_subset, y_test_subset, batch_size=BATCH_SIZE)\n",
    "print(f\"Test Set        : Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")\n",
    "\n",
    "print(\"Evaluating training set with model.evaluate() ...\")\n",
    "eval_results = nn.evaluate(X_train_scaled_subset, y_train_subset, batch_size=BATCH_SIZE)\n",
    "print(f\"Training Set    : Loss: {eval_results[0]}, Accuracy: {eval_results[1:]}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5974ce11-65de-4f70-859d-558c4b6b16c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "             Loss  Accuracy (Distance)  Accuracy (Rounded)\n",
      "count  256.000000           256.000000          256.000000\n",
      "mean     9.473647             0.694398            0.052257\n",
      "std      0.004241             0.000137            0.000344\n",
      "min      9.462664             0.693908            0.051369\n",
      "25%      9.470460             0.694305            0.052009\n",
      "50%      9.473690             0.694397            0.052243\n",
      "75%      9.476553             0.694501            0.052486\n",
      "max      9.488837             0.694753            0.053311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Offset'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code was used to determine where to find the single best result from\n",
    "# the prediction. It will be moved to the analsis notebook...\n",
    "\n",
    "col_offset = []\n",
    "col_loss = []\n",
    "col_acc_dist = []\n",
    "col_acc_round = []\n",
    "\n",
    "# Looping through individual inputs is horribly slow, but I specifically wanted this\n",
    "# so I could relate behaviors to what I could actually see.\n",
    "HOW_MANY = 10\n",
    "for _ in range(HOW_MANY):\n",
    "    which_input = random.randint(0, input.shape[0]-1)\n",
    "    this_input = input[which_input:which_input+1, :, :]\n",
    "    this_expected = expected[which_input:which_input+1, :, :]\n",
    "\n",
    "    raw_predicted = nn.predict(this_input, batch_size=BATCH_SIZE)\n",
    "    this_predicted = raw_predicted.astype(np.float64)\n",
    "\n",
    "    offsets = range(0, CHUNK_SIZE)\n",
    "    for offset in offsets:\n",
    "        # I don't know why these are different:\n",
    "        if INFER_TEXT:\n",
    "            offset_predicted = this_predicted[:, :, offset]\n",
    "        if INFER_KEY:\n",
    "            offset_predicted = this_predicted[:, offset, :]\n",
    "            \n",
    "        loss = modulo_distance_loss(this_expected, offset_predicted)\n",
    "        accuracy_distance = modulo_distance_accuracy(this_expected, offset_predicted)\n",
    "        accuracy_rounded = modulo_rounded_accuracy(this_expected, offset_predicted)\n",
    "\n",
    "        col_offset.append(offset)\n",
    "        col_loss.append(loss.numpy())\n",
    "        col_acc_dist.append(accuracy_distance.numpy())\n",
    "        col_acc_round.append(accuracy_rounded.numpy())\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Offset\": col_offset,\n",
    "    \"Loss\": col_loss,\n",
    "    \"Accuracy (Distance)\": col_acc_dist,\n",
    "    \"Accuracy (Rounded)\": col_acc_round \n",
    "}).set_index(\"Offset\")\n",
    "\n",
    "metrics_df = metrics_df.groupby(['Offset']).mean()\n",
    "print(metrics_df.describe())\n",
    "metrics_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488ae3d-b10f-40d7-826a-61fedba4cb2b",
   "metadata": {},
   "source": [
    "# Model Usefulness Spot-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4abd4fd4-831e-43a5-9351-c0c2cfa1be2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciphertext:\n",
      " 99,:0[\"=:&-!:Y\"8[],!Z8,0-)!8]#8=][,![,\"80``!`8-?8,:0[\"=:&-!:80[`8;)0=!`9&[,]8,%!8;.-)&=8`]+0&[38-])`#0=!8,!>,8&\"8&[`&=0,!`80\"8K!\n",
      "Decoded   :\n",
      " KJUQCNRCQHBDQ<T NOTE>AUBCMF\n",
      "PG\n",
      "DPOUFOUT BDDED BX TSBOTCRIBER AND QLBCED\n",
      "INTP THE QUCLIC DOMBIN< BPMEGBDE UFXT IS IODIDBTED AS >M\n",
      "\n",
      "Ciphertext:\n",
      " %A;+$(<B/A$<[$.</A+$( '\n",
      "A<%%*F$&,+E&/) +$)B.&\n",
      "$4> +5%%QQQP.$%%QQHH.$%%QQHP.$%%(</A+/A\n",
      "%%$C<,B.+$</+%(;&>A+ $H-$.& \n",
      "+',,+\n",
      "A;+$&  \n",
      "Decoded   :\n",
      " HJEDBFPRIS?LC?LMLTC BPGPTJ  \n",
      "T \n",
      "JCTALBPC?BTJ\n",
      "Q?DMNCCHBQWXXH   QWRXI   QWRXG   AMLTCLSM  ?TKJSIB?NLB?AE NTCO?S?\n",
      "L PPBFIIBPTEB? PP\n",
      "\n",
      "Ciphertext:\n",
      " VV$!W0#Y!5X1!L#U0-$1MU$WX81U-2UY-0$10$#UWZZ1ZUX)U$!W0#Y!5X1!UW0ZU=8WY1ZV50$-U$41U=%X85YUZ-9W50PUX-8Z2WY1U$1($U5#U50Z5YW$1ZUW#U?1\n",
      "Decoded   :\n",
      " EJTNAORCRHBER<V\n",
      "PPUF<BVCDNGAQHAEQPVGPUT\n",
      "BEEFE\n",
      "DY\n",
      "USCPTDSJCFS\n",
      "BOE\n",
      "QMBDFEAJOUP UIF QVCMJD EPNBJO<\n",
      "CPMEGBDF UFXU\n",
      "JT\n",
      "JOEJDBUFE BT\n",
      "2D\n",
      "\n",
      "Ciphertext:\n",
      " ==<(%-()/<:.A-:&-<(%-\"%]:\":''%/)`'- `.==!A-<(>#A$)$%/-FEC-!#==-<.`'/]`<%$-!A-.)#(`.$-#.` ]%A-== )<(-\"%.;)//):'=<:=#:'':\"-<().] `\n",
      "Decoded   :\n",
      " JJTIGBJKTTORJ ME SGD PDKNONMMDQG L?U Q ?AM RGTBNAGCCQ MPTACB \n",
      " TRANRK\n",
      "TDC?AM QHBF\n",
      "RC?CQ\n",
      "VKDL B\n",
      "UHSG?PDQLHRRHNM SN BNMMNO?SGHQKU \n",
      "\n",
      "Ciphertext:\n",
      " ==<(%-\".)'#%==!A-')#:]:-;`#()`?%]])==<.`'/]`<%$-!A- 6-[6-;`..):<<==#:'<%'</==-)'<.:$>#<):'=-A:><(-<6-CMDGCFHKMKF=-:&&)#%-<6-DGMF\n",
      "Decoded   :\n",
      " JJTIGBRSJODEAACL MICOLO MACGHAVEKKH  TRANSL\n",
      "TEC?AM U? K>\n",
      "NBSRIOTT  BONTEMTS  ?HMTROCTCSHNM ?LITSG?S< LSMWVYYYYYWCCODDFAD S?\n",
      "MRVS\n",
      "\n",
      "Ciphertext:\n",
      " 99=];?:&$%,8S=T8\n",
      "HGD8-?8=])][!)8!.$![!8=38*0=]-\"399S[],!Z8;:]*!=,8$.,![-!:$Y\"83 &;8&[=).`!\"8,%!8&+0$!\"8#:]+8,%!8-]](3T998-)]]`8-\n",
      "Decoded   :\n",
      " KJKTSWQHFFR? K>EWDEHCEX COLONDK?DTFDMD?B> JACOBS<\n",
      "\n",
      "?SPUE<AQSPKFDU GUTENBERG/U\n",
      "<YIQ JODMVEFT UIF JNBHFT FSPN UIF CPPL</CB\n",
      "CMPPE\n",
      "C\n",
      "\n",
      "Ciphertext:\n",
      " 00+#<*-.&-]00= 9.&;[-,9&;==#,00AFEA00+#<*-.&-]9;\"9.&#9[-..#\"39$;\"[#39R9';>#\"9;$9-9`;[[;]K>#-+.&0#``+#,*-,.*`-+9-]!9`*<*++00.&;[-\n",
      "Decoded   :\n",
      " KJSIVIBTHBN \n",
      "BX THOMAS GOBBDS  KNPQBDMDUH\n",
      "TG\n",
      "M?OQ?TGD?L\n",
      "TTDQ< ENRLD<  HSPWER OF A COMMONBMD\n",
      "KSG ECCKESHASTHCAK AND CHUHLL  THOMA\n",
      "\n",
      "Ciphertext:\n",
      " ,,MABL\"?M?QM\"P.L\"IKH>N<?>\"/R\"LM?O?\"/HGG?K[,,MA?\" BK?LB>?\"<A.ML\"H , K.GDEBG\">?E.GH\"KHHL?O?EM,,K.>BH\".>>K?LL?L\"MH\"MA?\".F?KB<.G\"I?H\n",
      "Decoded   :\n",
      " FJNILUBFPCRS?R Q QQNBQACA?AR\n",
      "RSCRC?AQMLCQ>  RID EPQCQHCC?BPBRS QE\n",
      "EQAQJKHM\n",
      "CCQAQO ROOSCRDPS  QBCPN \n",
      "CCRDRSCR RN RHD \n",
      "QDQIC\n",
      "Q\n",
      "QEQ\n",
      "\n",
      "Ciphertext:\n",
      " AAQSPEVDFE\n",
      "CZ\n",
      "HSFH\n",
      "XFFLT.\n",
      "TIBSPO\n",
      "BOE\n",
      "UIF\n",
      "POMJOF\n",
      "EJTUSJCVUFEAQSPPGSFBEJOH\n",
      "UFBN\n",
      "BU\n",
      "IUUQ\"<<XXX/QHEQ/OFUAA\n",
      "EBWF\n",
      "EBXTPOA\n",
      "XJUIA\n",
      "UIF\n",
      "BJ\n",
      "Decoded   :\n",
      " EESQKBS\n",
      "CBFFTDHOCEDHEEKS DNHDTQP\n",
      "LOE\n",
      "OIF\n",
      "OPNJOF LJSTSJDTSEDCQRNNDPCBCGLDBNECNALTAMTTQ>??OUT?PIFR?OGUDD\n",
      "LEUE LEUSQPD\n",
      "OITHD OIF\n",
      "LJ\n",
      "\n",
      "Ciphertext:\n",
      " ? LLC>MD>EPCCL>E \n",
      "JCQ??\n",
      "W>JSAW>K SB>KMLREMKCPW??R \n",
      "JC>MD>AMLRCLRQ??>AF NRCP>G>KPQ\">P AFCJ>JWLBC>GQ>QSPNPGQCB?>AF NRCP>GG>K RRFCU\n",
      "Decoded   :\n",
      " FKORJBQIAOSFFOAMADOFT\n",
      "ACP\n",
      "PTEV O\n",
      "QF OPNTGNMERV \n",
      "O\n",
      "BOF OG MNNTEMTS \n",
      " NH\n",
      "OTER N ORS> OAMGEL NULEE MS PTRQSIRED ?MG\n",
      "OSEQ MH N\n",
      "PSGEU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FILES_TO_CHECK = 10\n",
    "if INFER_TEXT:    \n",
    "    CHUNKS_TO_CHECK = 1\n",
    "else:\n",
    "    CHUNKS_TO_CHECK = 200\n",
    "\n",
    "good=0\n",
    "bad=0\n",
    "for _ in range(FILES_TO_CHECK):\n",
    "    sid = random.choice(list(sid_to_c.keys()))\n",
    "    cipher_file_db = random.choice(sid_to_c[sid])\n",
    "    ciphertext_path = cipher_file_db.path\n",
    "    ciphertext = helpers.read_text_file(ciphertext_path)\n",
    "    length = min(CHUNK_SIZE * CHUNKS_TO_CHECK, len(ciphertext))\n",
    "    ciphertext = ciphertext[0:length]\n",
    "    \n",
    "    if INFER_KEY:\n",
    "        cracker = Caesar_Cracker(X_scaler, nn, None)\n",
    "    \n",
    "        with db.get_session() as session:\n",
    "            correct_key = int(db.get_key_by_id(session, cipher_file_db.key_id).value)\n",
    "        \n",
    "        inferred_key = cracker.infer_key_with_model(ciphertext)\n",
    "\n",
    "        if correct_key == inferred_key:\n",
    "            good += 1\n",
    "        else:\n",
    "            bad += 1\n",
    "    if INFER_TEXT:\n",
    "        cracker = Caesar_Cracker(X_scaler, None, nn)\n",
    "    \n",
    "        with db.get_session() as session:\n",
    "            correct_key = int(db.get_key_by_id(session, cipher_file_db.key_id).value)\n",
    "            \n",
    "        inferred_text = cracker.infer_text_with_model(ciphertext)\n",
    "        print(\"Ciphertext:\\n\", ciphertext[0:128])\n",
    "        print(\"Decoded   :\\n\", inferred_text[0:128])\n",
    "        print()\n",
    "\n",
    "if bad > 0:\n",
    "    print(good, bad, float(good)/float(good+bad))\n",
    "    print(f\"Caesar chance would be {float(1)/float(len(encoders.CHARSET))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
